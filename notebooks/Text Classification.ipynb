{
 "metadata": {
  "name": "",
  "signature": "sha256:c21c01905575b909d53a8516107cce0952c1e1f9cfaf6dda13de1aaf4fce8d3f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Detecting Copied Text Using Unordered Word Sets and a Naive Bayes Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Goal: Identify portions of text that have been copied from a Wikipedia article in one language to an article in another language.\n",
      "\n",
      "To achieve this goal, we need a method that can match pieces of text.  The method should account for the following:\n",
      "\n",
      "* Word order may vary locally (e.g., \"the painted red house\" can become \"the house painted red\").\n",
      "* Individual words may be dropped, added, or changed (e.g., \"the painted red house\" can become \"the red colored house\").\n",
      "* Units of copied text may be as small as a sentence or clause.\n",
      "\n",
      "To meet the criteria, we propose classifying matching each word using its $(N_w - 1)/2$ neighboring words on its left and right. In other words, we propose using a sliding window of $N_w$ linearly-located words to classify each word.  The group of words will be represented as an unordered set to handle local variations in word order.\n",
      "\n",
      "To handle misspellings, we may want to cluster words by their edit distances.\n",
      "\n",
      "Two classification methods appear promising:\n",
      "\n",
      "* Nearest neighbor using cosine similarity -- we can either use word occurence or weight words by their inverse-frequency\n",
      "* Bernoulli Naive Bayes (we don't consider word counts)\n",
      "\n",
      "We need ways to evaluate the choices of $N_w$ and the classification method.  "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preparing Test Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The English version of the Wikipedia articles can be downloaded [here](http://dumps.wikimedia.org/enwiki/).  I used the smallest file of the complete pages, current versions only, in XML format, bzipped.\n",
      "\n",
      "1. Parse XML files\n",
      "2. Strip mediawiki formatting\n",
      "3. Remove punctuation and make letters lowercase\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first step is to extract the articles from the XML dump."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "def read_articles(flname):\n",
      "    tree = ET.parse(flname)\n",
      "    root = tree.getroot()\n",
      "    formatted_articles = []\n",
      "    for page in root.iterfind(\"{http://www.mediawiki.org/xml/export-0.8/}page\"):\n",
      "        article_text = None\n",
      "        title = page.find(\"{http://www.mediawiki.org/xml/export-0.8/}title\").text\n",
      "        revision = page.find(\"{http://www.mediawiki.org/xml/export-0.8/}revision\")\n",
      "        text = revision.find(\"{http://www.mediawiki.org/xml/export-0.8/}text\").text\n",
      "        formatted_articles.append((title, text))\n",
      "    return formatted_articles\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles = read_articles(\"data/enwiki-20140707-pages-meta-current1.xml-p000000010p000010000\")\n",
      "articles = filter(lambda t: not t[0].startswith(\"Talk:\"), articles)\n",
      "print len(articles)\n",
      "articles = filter(lambda t: len(t[1]) > 5000, articles)\n",
      "print len(articles)\n",
      "sampled_articles = list(random.sample(articles, 30))\n",
      "training_articles = sampled_articles[:10]\n",
      "validation_articles = sampled_articles[10:20]\n",
      "near_match_articles = sampled_articles[20:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6317\n",
        "3942\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second step is to remove the mediawiki formatting."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def remove_block_regex(text, start_delim, end_delim):\n",
      "    block_regex = re.compile(start_delim + r\".+?\" + end_delim, flags=re.DOTALL)\n",
      "    new_string = \"\"\n",
      "    last_end = 0\n",
      "    for match in block_regex.finditer(text):\n",
      "        new_string += text[last_end:match.start(0)] + \" \" \n",
      "        last_end = match.end(0)\n",
      "    new_string += text[last_end:]\n",
      "    \n",
      "    return new_string\n",
      "\n",
      "def replace_link_block(block):\n",
      "    if block.startswith(\"[[image:\") or \\\n",
      "        block.startswith(\"[[file:\"):\n",
      "            return \" \"\n",
      "    elif block[1] != \"[\":\n",
      "        start = block.find(\" \")\n",
      "        if start == -1:\n",
      "            return \" \"\n",
      "        else:\n",
      "            return block[start+1:-1]\n",
      "    elif \"|\" in block:\n",
      "        start = block.find(\"|\")\n",
      "        return block[start+1:-2]\n",
      "    \n",
      "    return block[2:-2]\n",
      "\n",
      "def substitute_links(text):\n",
      "    pos = 0\n",
      "    start_pos = 0\n",
      "    while pos < len(text):\n",
      "        if text[pos:pos+2] == \"[[\":\n",
      "            start_pos = pos\n",
      "            pos += 2\n",
      "        elif text[pos] == \"[\":\n",
      "            start_pos = pos\n",
      "            pos += 1\n",
      "        elif text[pos:pos+2] == \"]]\":\n",
      "            block = text[start_pos:pos+2]\n",
      "            block = replace_link_block(block)\n",
      "            text = text[:start_pos] + block + text[pos+2:]\n",
      "            pos = 0\n",
      "        elif text[pos] == \"]\":\n",
      "            block = text[start_pos:pos+1]\n",
      "            block = replace_link_block(block)\n",
      "            text = text[:start_pos] + block + text[pos+1:]\n",
      "            pos = 0\n",
      "        else:\n",
      "            pos += 1\n",
      "            \n",
      "    return text\n",
      "\n",
      "def remove_tail(text):\n",
      "    headers = [\"==See Also==\", \"== See Also ==\", \"==References==\", \"== References ==\",\n",
      "                \"==External Links==\", \"== External Links ==\", \"==Further Reading==\",\n",
      "                \"== Further Reading ==\"]\n",
      "    positions = [text.find(s.lower()) for s in headers]\n",
      "    positions = filter(lambda p: p != -1, positions)\n",
      "    \n",
      "    if len(positions) == 0:\n",
      "        return text\n",
      "    \n",
      "    pos = min(positions)\n",
      "    \n",
      "    return text[:pos]\n",
      "\n",
      "TAG_REGEX = re.compile(r\"<\\s*(\\w+).+?/\\1\\s*>\", flags=re.DOTALL)\n",
      "\n",
      "def remove_html_tags(text):\n",
      "    pos = 0\n",
      "    start_pos = 0\n",
      "    last_block_end = 0\n",
      "    new_string = \"\"\n",
      "    while pos < len(text):\n",
      "        if text[pos] == \"<\":\n",
      "            start_pos = pos\n",
      "        elif text[pos:pos+2] == \"/>\":\n",
      "            new_string += text[last_block_end:start_pos] + \" \"\n",
      "            pos += 2\n",
      "            last_block_end = pos\n",
      "        pos += 1\n",
      "    new_string += text[last_block_end:]\n",
      "    text = new_string\n",
      "    \n",
      "    new_string = \"\"\n",
      "    last_end = 0\n",
      "    for match in TAG_REGEX.finditer(text):\n",
      "        new_string += text[last_end:match.start(0)] + \" \" \n",
      "        last_end = match.end(0)\n",
      "    new_string += text[last_end:]\n",
      "    \n",
      "    return new_string\n",
      "        \n",
      "\n",
      "def remove_wiki_formatting(text):\n",
      "    text = text.lower()\n",
      "    \n",
      "    text = remove_tail(text)\n",
      "    \n",
      "    text = remove_block_regex(text, r\"\\{\\{\", r\"\\}\\}\")\n",
      "    text = substitute_links(text)\n",
      "    \n",
      "    text = remove_block_regex(text, r\"<!--\", r\"-->\")\n",
      "    text = remove_html_tags(text)\n",
      "   \n",
      "    text = text.replace(\">\", \" \")\n",
      "    text = text.replace(\"<\", \" \")\n",
      "    text = text.replace(\"-\", \" \")\n",
      "    text = text.replace(\"&nbsp;\", \" \")\n",
      "    text = text.replace(\"&gt;\", \">\")\n",
      "    text = text.replace(\"&lt;\", \"<\")\n",
      "    text = text.replace(\"&amp;\", \" \")\n",
      "    text = text.replace(\"|\", \" \")\n",
      "    text = text.replace(\"/\", \" \")\n",
      "    text = text.replace(\"}}\", \" \")\n",
      "    text = text.replace(\"{{\", \" \")\n",
      "    \n",
      "    text = text.replace(\"===\", \"\")\n",
      "    text = text.replace(\"==\", \"\")\n",
      "    text = text.replace(\"=\", \"\")\n",
      "    text = text.replace(\"'''\", \"\")\n",
      "    text = text.replace(\"''\", \"\")\n",
      "    text = text.replace(\".\", \"\")\n",
      "    text = text.replace(\",\", \"\")\n",
      "    text = text.replace(\"\\\"\", \"\")\n",
      "    text = text.replace(\"(\", \"\")\n",
      "    text = text.replace(\")\", \"\")\n",
      "    text = text.replace(\"'\", \"\")\n",
      "    text = text.replace(\"?\", \"\")\n",
      "    text = text.replace(\";\", \"\")\n",
      "    text = text.replace(\":\", \"\")\n",
      "    text = text.replace(\"!\", \"\")\n",
      "    text = text.replace(\"*\", \"\")\n",
      "    \n",
      "    return \" \".join(text.split())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stripped_training_articles = map(lambda t: (t[0], remove_wiki_formatting(t[1])), training_articles)\n",
      "stripped_validation_articles = map(lambda t: (t[0], remove_wiki_formatting(t[1])), validation_articles)\n",
      "stripped_near_match_articles = map(lambda t: (t[0], remove_wiki_formatting(t[1])), near_match_articles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Extraction of Word Sets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have each article in unformatted, plain text, we can extract the unordered word sets.  The word sets are found by scanning over the articles' text with a sliding window.  For each word, we extract the word, its $n$ neighbors to the left, and its $n$ neighbors to the right.  We represent each word set as a tuple containing an unordered set of the extracted words, the index of the center word, and the title of the article."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_word_sets(article, window_length):\n",
      "    title, text = article\n",
      "    words = text.split()\n",
      "    word_sets = list()\n",
      "    for i in xrange(len(words) - window_length):\n",
      "        word_set = ((title, i + ((window_length - 1) / 2)), frozenset(words[i:i+window_length]))\n",
      "        word_sets.append(word_set)\n",
      "    return word_sets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preparation of Data Sets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Training and validation sets for four data sets:\n",
      "\n",
      "* Random word sets -- Our null hypothesis.  Want to look at the distributions for randomly-drawn word sets.\n",
      "* Perfect matches -- $H_0$: Duplicate word sets are placed in the training and validation sets along with randomly-drawn word sets.  Mimic cases where there is 1 good perfect match among many random documents.\n",
      "* Off-by-1 matches -- $H_1$: Word sets and their nearest neighbor are placed in the training and validation sets, respectively, along with randomly-drawn word sets.  Mimic cases where there is 1 match with 1 word differing among many random documents.\n",
      "* Off-by-2 matches -- $H_2$: Word sets and their neighbor 2 words down are placed in the training and validation sets, respectively, along with randomly-drawn word sets.  Mimic cases where there is 1 match with 2 word differing among many random documents.\n",
      "\n",
      "These data sets allow us to measure our prediction accuracy against standard \"background noise.\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_article_word_sets = map(lambda article: extract_word_sets(article, 5), stripped_training_articles)\n",
      "validation_article_word_sets = map(lambda article: extract_word_sets(article, 5), stripped_validation_articles)\n",
      "near_match_article_word_sets = map(lambda article: extract_word_sets(article, 5), stripped_near_match_articles)\n",
      "training_word_sets = random.sample(reduce(lambda x, y: x + y, training_article_word_sets), 3000)\n",
      "validation_word_sets = random.sample(reduce(lambda x, y: x + y, validation_article_word_sets), 3000)\n",
      "\n",
      "word_set_pairs_0 = []\n",
      "for article_word_sets in near_match_article_word_sets:\n",
      "    for i in xrange(len(article_word_sets)):\n",
      "        word_set_pairs_0.append((article_word_sets[i], article_word_sets[i]))\n",
      "\n",
      "word_set_pairs_1 = []\n",
      "for article_word_sets in near_match_article_word_sets:\n",
      "    for i in xrange(len(article_word_sets) - 1):\n",
      "        word_set_pairs_1.append(article_word_sets[i:i+2])\n",
      "        \n",
      "word_set_pairs_2 = []\n",
      "for article_word_sets in near_match_article_word_sets:\n",
      "    for i in xrange(len(article_word_sets) - 2):\n",
      "        word_set_pairs_2.append((article_word_sets[i], article_word_sets[i+2]))\n",
      "        \n",
      "\n",
      "training_word_set_0 = training_word_sets[:1500]\n",
      "validation_word_set_0 = validation_word_sets[:1500]\n",
      "validation_set_labels_0 = dict()\n",
      "for ws1, ws2 in random.sample(word_set_pairs_0, 1500):\n",
      "    training_word_set_0.append(ws1)\n",
      "    validation_word_set_0.append(ws2)\n",
      "    validation_set_labels_0[ws2[0]] = ws1[0]\n",
      "        \n",
      "        \n",
      "training_word_set_1 = training_word_sets[:1500]\n",
      "validation_word_set_1 = validation_word_sets[:1500]\n",
      "validation_set_labels_1 = dict()\n",
      "for ws1, ws2 in random.sample(word_set_pairs_1, 1500):\n",
      "    training_word_set_1.append(ws1)\n",
      "    validation_word_set_1.append(ws2)\n",
      "    validation_set_labels_1[ws2[0]] = ws1[0]\n",
      "    \n",
      "training_word_set_2 = training_word_sets[:1500]\n",
      "validation_word_set_2 = validation_word_sets[:1500]\n",
      "validation_set_labels_2 = dict()\n",
      "for ws1, ws2 in random.sample(word_set_pairs_2, 1500):\n",
      "    training_word_set_2.append(ws1)\n",
      "    validation_word_set_2.append(ws2)\n",
      "    validation_set_labels_2[ws2[0]] = ws1[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(training_word_sets), len(validation_word_sets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3000 3000\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print training_word_sets[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(('Bell Labs', 1293), frozenset([u'being', u'were', u'from', u'emitted', u'waves']))\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Examination of Word Set Distance Distributions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To determine the viability of using a Naive Bayes approach, we want to examine the distribution of overlaps between the word sets.  The distance function is the number of words in $s_1$ that are not in $s_2$ or the difference of $s_1$ and $s_2$ given by:\n",
      "\n",
      "$$\n",
      "d_a(s_1, s_2) = | s_1 - s_2 |\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "def compute_asymm_dist_distr(word_set1, word_set2):\n",
      "    min_dist_distribution = defaultdict(lambda: 0)\n",
      "    for key, s1 in word_set1:\n",
      "        min_dist = len(s1)\n",
      "        for key2, s2 in word_set2:\n",
      "            dist = 0\n",
      "            for w in s1:\n",
      "                if w not in s2:\n",
      "                    dist += 1\n",
      "            min_dist = min(min_dist, dist)\n",
      "            if min_dist == 0:\n",
      "                break\n",
      "        min_dist_distribution[min_dist] += 1\n",
      "    return min_dist_distribution\n",
      "\n",
      "dist_random_distr = compute_asymm_dist_distr(validation_word_sets, training_word_sets)\n",
      "dist_offset0_distr = compute_asymm_dist_distr(validation_word_set_0, training_word_set_0)\n",
      "dist_offset1_distr = compute_asymm_dist_distr(validation_word_set_1, training_word_set_1)\n",
      "dist_offset2_distr = compute_asymm_dist_distr(validation_word_set_2, training_word_set_2)\n",
      "\n",
      "distances_random = list(sorted(dist_random_distr.keys()))\n",
      "distances_offset0 = list(sorted(dist_offset0_distr.keys()))\n",
      "distances_offset1 = list(sorted(dist_offset1_distr.keys()))\n",
      "distances_offset2 = list(sorted(dist_offset2_distr.keys()))\n",
      "densities_random = [dist_random_distr[d] / float(sum(dist_random_distr.values())) for d in distances_random]\n",
      "densities_offset0 = [dist_offset0_distr[d] / float(sum(dist_offset0_distr.values())) for d in distances_offset0]\n",
      "densities_offset1 = [dist_offset1_distr[d] / float(sum(dist_offset1_distr.values())) for d in distances_offset1]\n",
      "densities_offset2 = [dist_offset2_distr[d] / float(sum(dist_offset2_distr.values())) for d in distances_offset2]\n",
      "\n",
      "plt.plot(distances_random, densities_random, color=\"c\", label=\"Random\")\n",
      "plt.hold(True)\n",
      "plt.plot(distances_offset0, densities_offset0, color=\"r\", label=\"Offset 0\")\n",
      "plt.plot(distances_offset1, densities_offset1, color=\"g\", label=\"Offset 1\")\n",
      "plt.plot(distances_offset2, densities_offset2, color=\"b\", label=\"Offset 2\")\n",
      "plt.xlabel(\"Distance (missing words)\", fontsize=16)\n",
      "plt.ylabel(\"Density\", fontsize=16)\n",
      "plt.legend(loc=\"upper right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "<matplotlib.legend.Legend at 0x6141e90>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAERCAYAAAB/4wAeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXdcU+f3xz9h740geyniQsWFRYu2ddZt66qrzqo426pV\nq9ZR97Z11FG1bn/WCdqqVFABcYBbUGZA2Xtknd8fEb4ORoCb3CTc9+v1vF4k97nn+RBCTp5xzuER\nETg4ODg4OMrQYFsABwcHB4dywTkGDg4ODo734BwDBwcHB8d7cI6Bg4ODg+M9OMfAwcHBwfEenGPg\n4ODg4HgPhTuGoKCgnk2aNHnWqFGjmDVr1syrqE9wcLB/69at7zdv3vyRv79/sIIlcnBwcNRreIqM\nYxCLxZqenp7P//3338/t7e357dq1u3P06NHhXl5eT8v65OTkmH3yySc3L1++3MPBwSE5IyPDysrK\nKkNhIjk4ODjqOQqdMURERLT38PCIdXFxidfW1hYOGzbs2NmzZ/u/2+fIkSMjBg8efNrBwSEZADin\nwMHBwaFYtBQ5GJ/Pt3d0dEwqe+zg4JAcHh7e4d0+MTExjYRCoXbXrl2v5+fnG8+cOXPLqFGjDr3b\nh8fjceHaHBwcHLWAiHjV9VHojEGWD3ShUKh97969NpcuXep9+fLlHsuXL18cExPT6MN+RMQ1IixZ\nsoR1DcrSuNeCey2416LqJisKnTHY29vzk5KSHMseJyUlOZYtGZXh6OiYZGVllaGvr1+sr69f3KVL\nlxtRUVHejRo1ilGkVg4ODo76ikJnDG3bto2MiYlpFB8f7yIQCHSOHz8+tF+/fufe7dO/f/+zoaGh\nfmKxWLOoqMggPDy8Q9OmTZ8oUicHBwdHfUahMwYtLS3R9u3bp/fo0eOyWCzWHD9+/F4vL6+nu3bt\nmgwAkydP3tWkSZNnPXv2DGrZsmW0hoaGZOLEiXs4x1A5/v7+bEtQGrjX4n9wr8X/4F6LmqPQ46pM\nwePxSBV1c3BwcLAJj8cDybD5rNAZAwcHR/3FwsIC2dnZbMuoF5ibmyMrK6vW93MzBg4ODoXw9tsq\n2zLqBZW91rLOGLhcSRwcHBwc78E5Bg4ODg6O9+AcAwcHBwfHe3COgYODg0NBLF26FKNGjWJbRrVw\njoGDg6Pe4+LiAgMDAxgbG8PW1hajRo1CXl4e4+PweNXu+yoFnGPg4FBD3ggEEEgkbMtQGXg8Hi5c\nuID8/HxERUXh4cOHWLFiBduyWINzDBwcagYR4bOoKPzw8iXbUlQSGxsbdO/eHY8fPwYArF69Gh4e\nHjAxMUGzZs3w999/l/c9cOAA/Pz88MMPP8DCwgJubm4ICgoqvx4XF4dPP/0UJiYm6N69OzIy3q8i\ncO7cOTRr1gzm5ubo2rUrnj17Vn7NxcUF69evR8uWLWFsbIzx48fjzZs36NWrF0xNTfHFF18gJydH\nLq8B5xg4ONSMf7OzIZRIcDQtDY8KC9mWozKUnftPTk5GUFAQOnSQVgTw8PBAaGgo8vLysGTJEnzz\nzTd48+ZN+X0RERFo0qQJMjMz8eOPP2L8+PHl10aMGIF27dohMzMTixcvxp9//lm+nPTixQuMGDEC\nW7duRUZGBnr37o2+fftCJBIBkM5i/u///g9Xr17F8+fPceHCBfTq1QurV69GWloaJBIJtm7dKpfX\nggtw4+BQM758+BADrKxQKpHgVHo6rnl7K8XadnUBbrzgYEbGoVrkRnJxcUFmZiZ4PB4KCgrQv39/\nnD59GhoaH393bt26NZYtW4Z+/frhwIEDWLlyJWJipMmfi4qKYGRkhNevX6OkpATu7u7Iy8uDvr4+\nAGDkyJHQ1NTEwYMHsXz5cjx+/BjHjh2T6iaCo6Mjjhw5gi5dusDV1RWrVq3C8OHDAQBDhgyBjY0N\nduzYAQDYvn07rl69ijNnznyksa4BblxKDA4ONeJFUREi8vJwsmlTaGtoYHdKCk6mp+PrBg3YllYt\ntflAZwoej4ezZ8+iW7duuHHjBvr27YvIyEi0b98eBw8exKZNmxAfHw8AKCgoQGZmZvm9tra25T8b\nGBiU90lLS4O5uXm5UwAAZ2dnJCdLKw2kpKTAycnpPQ2Ojo7g8/nlz9nY2JT/rK+v/95jPT09FBQU\nMPQKvA+3lMTBoUZs5fMxyc4O+pqa0OLxsK1RI3z/8iUKxWK2pakMXbp0QUBAAObNm4fExERMnDgR\nO3bsQFZWFrKzs9G8eXOZUns0bNgQ2dnZKCoqKn8uISGh/Gd7e/v3HhMRkpKSYG9vX6lNRa2UcI6B\ng0NNyBGJcOTNG0y1syt/rouZGfxMTfFrYiKLylSPWbNmISIiAsnJydDQ0ICVlRUkEgn279+PR48e\nyWTD2dkZbdu2xZIlSyAUChEaGooLFy6UX//qq69w8eJFXLt2DUKhEBs2bICenh46deokr19LZjjH\nwMGhJuxNTUUvCwvY6eq+9/w6d3fsTEnBy+JilpSpHlZWVhgzZgzWrVuHuXPnwtfXF7a2tnj06BH8\n/PzK+/F4vI/2b959fOTIEYSHh8PCwgK//PILxowZU37N09MThw8fRkBAAKytrXHx4kWcP38eWlqV\nr/C/a7uisZmC23zm4FADRETwCA/HiaZN0d7E5KPrqxMTcSs3F+datGBBnRQuu6ri4LKrcnBw4FxG\nBux0dCp0CgAw28EBz4qKcOmdTVMOjsrgHAMHhxqwOTkZsxwcKr2uq6GBzR4emBkbi1IuIpqjGjjH\nwMGh4tzLz0d8SQkGWVtX2a+3pSW8DAyw6e1xSQ6OyuAcAweHirMlORnT7O2hJcNG5CYPD6xPSgK/\ntFQByjhUFc4xcHCoMK8FApzLzMTEhg1l6u+ur48pdnZcHiWOKuEcAweHCvM7n49hDRrAQltb5nsW\nODkhNDcXN+SUgI1D9eEcAweHilIikWBXaipmVBEpWxGGmppY7+6OgJgYiLjjoxwVwDkGDg4V5Vha\nGloZGcHL0LDG935lbQ1LbW3sSkmRgzIOVYdzDBwcKggRVXtEtSp4PB62NmqEZfHxyBAKGVan3owb\nNw4WFhbo2LEjAOD333+HjY0NTExMkJ2dzbI6ZuAcAweHCnIjNxclEgm6m5vX2kZzQ0MMb9AAC1+9\nYlCZanPgwAG0aNEChoaGaNiwIaZOnYrc3Nzy6yEhIfj333/B5/MRFhYGoVCIuXPn4urVq8jLy4N5\nLf8ewcHBcHR0rLbfvHnzYGVlBSsrK8yfP79WY8kC5xg4OFSQzcnJmGlvD4065spZ5uqKs5mZuJuf\nz5Ay1WXDhg2YP38+NmzYgLy8PISFhSEhIQFffPEFhG9nVQkJCXBxcSlPpV1Wd8HLy0vu+nbt2oWz\nZ88iOjoa0dHROH/+PHbt2iWfwYhI5ZpUNgdH/eRlURFZhoZSgUjEiL0/UlLI9+5dEkskjNirDGX+\nv83NzSUjIyM6efLke88XFBSQtbU17du3j/bu3Ut6enqkqalJRkZGNHz4cDI0NCQej0dGRkb02Wef\nERHRrFmzqEGDBmRiYkItWrSgR48eERFRSUkJzZ07l5ycnMjGxoamTJlCxcXFVFBQQHp6eqShoUFG\nRkZkbGxMqampH2n09fWlPXv2lD/et28fdezYscLfp7LX+u3z1X/GytKJyRYYGNjT09PzmYeHR8zq\n1avnfXj9+vXr/iYmJrmtWrW636pVq/vLly9f9JFoJX6DcXDIm9kxMfRDbCxj9sQSCbWLjKQ/K/gw\nYhJl/r8NDAwkLS0tEovFH10bM2YMDR8+nIiIDhw4QH5+fuXX4uPjicfjld8XFBREPj4+lJubS0RE\nz549K/+QnzVrFvXv35+ys7MpPz+f+vbtSwsWLCAiouDgYHJwcKhSo6mpKUVERJQ/joyMJGNj4wr7\n1tUxKLSCm1gs1pw+ffr2f//993N7e3t+u3bt7vTr1++cl5fX03f7ffrpp/+dO3eunyK1cXCoAnki\nEQ68fo0HbdsyZlPjbUGfgY8eob+VFUyrSPssV5hKIV2LI7gZGRmwsrKqsJSnra0t7t2799b0+7Y/\nfKyjo4P8/Hw8ffoU7dq1g6enZ3m/PXv2IDo6GmZmZgCABQsWYOTIkVi1apVMWWcLCgpgampa/tjE\nxEQ9KrhFRES09/DwiHVxcYnX1tYWDhs27NjZs2f7f9iPZEgLy8FRHznw+jU+NzeHk54eo3Y7mJig\np4UFfnlbvpIVpEsYdW+1wMrKChkZGZBUkGAwNTUV1tXkoSqja9eumD59OqZNmwYbGxtMnjwZ+fn5\nSE9PR1FREXx8fGBubg5zc3P06tULGRkZMms0MjJCXl5e+ePc3FwYGRnJfH9NUKhj4PP59o6Ojkll\njx0cHJL5fP570Tk8Ho9u3brVydvbO6p3796Xnjx50rQiW0u//hpLly7F0qVLEcxQEXEODmVGQoSt\nfD5m1vKIanX86uaGg2/e4GlhoVzsKzO+vr7Q1dXF6dOn33u+oKAAQUFB+Oyzz2S2FRAQgMjISDx5\n8gQvXrzAunXrYG1tDX19fTx58gTZ2dnIzs5GTk5O+Qe9LAV3mjVrhgcPHpQ/joqKQvPmzau8Jzg4\nuPxzcunSpTL/DgqdM/J4vGrdeZs2be4lJSU5GhgYFAUGBvYaMGDA3y9evGj8Yb+lmZlADX5RDg5V\n52JmJsy1tNCpkpoLdcVGRweLnJ0xIzYWV1q2lFt1MGXE1NQUS5YsQUBAAExMTNCtWzfw+XxMnToV\njo6OGDVqlEx2IiMjIRaL0aZNGxgYGEBPTw+amprg8XiYOHEiZs2ahe3bt8Pa2hp8Ph+PHz9G9+7d\nYWNjg8zMTOTl5cGkkr/v6NGjsXHjRvTu3RtEhI0bN2LmzJlV6vH394e/v3/542XLlsn0eyh0xmBv\nb89PSkoqP6yblJTk6ODg8F4OYGNj43wDA4MiAOjVq1egUCjUzsrKsvjI2IMHAJc+mKMeURbQJs8P\n7Kl2dkgVCHCmBksc6sIPP/yAVatW4fvvv4epqSk6duwIZ2dnXL16Fdpvc1FVV8ozLy8PkyZNgoWF\nBVxcXGBlZYUffvgBALBmzRp4eHigY8eOMDU1xRdffIEXL14AAJo0aYLhw4fDzc0NFhYWeP369Uf6\nJk+ejL59+6JFixZo2bIl+vbti0mTJsnnxZBlh5qpJhQKtdzc3F7GxcW5lJaW6nh7ez948uSJ17t9\nXr9+bSORSHhEhPDw8PbOzs7xH9oBQDRxItHq1VXu4nNwqAvR+fnU8OZNKq3g1AzTXMvKIufbt6mQ\noeOwZUCJTyWpG5W91lDGU0laWlqi7du3T+/Ro8dlsVisOX78+L1eXl5Pd+3aNRkAJk+evOvUqVND\nfv/99++0tLREBgYGRceOHRtWobFRo4ApU4Aff2TuNAMHh5Kyhc/HVHt76FRwaoZpupqbo72xMdYm\nJWGpi4vcx+NQPnhUy118NuHxeERiMeDuDpw+DbRpw7YkDg65kS4QoHFEBF60bw9rHR2FjJlYUoI2\nd+8i0scHLgydgKqsQD0H81T2Wr99vtpv0qqbEkNDA/jmG+DQIbaVcHDIld2pqRhkZaUwpwAATnp6\nmOXggDmxsQobk0N5UF3HAEiXk44eBUQitpVwcMgFgUSC3+R4RLUqvnd0RFRBAf7JylL42BzsotqO\noXFjwMUF+OcftpVwcMiFk+npaGJggJZyCmSqCj0NDWzy8MCM2FgIKgj84lBfVNsxANJZA7ecxKGG\nEElrLrAxWyijr6UlXPT0sI3PZ00Dh+JRfccwdChw8SLwTqg4B4c6cDsvD9kiEfpYWrKmgcfjYYuH\nB35NTERqaSlrOjgUi+o7BisroGtX6ekkDg41YnNyMmbY20OT5ePYjQ0MMN7WFvO4gj71BtV3DAC3\nnMShdiSWlODf7GyMtbVlWwoAYJGzM67l5ODWO9XM6itcaU9V4csvgagoIDGRbSUcHIywg8/HGFtb\nmLCVAvsDjLW0sNbNDdNjYiBW41gEZS7tef36dXTt2hVmZmZwdXWt1Tiyoh6OQVcXGDIE+OsvtpVw\ncNSZQrEYe1+/RoC9ffWdFcjwBg1gpKmJP1JT2ZYiF5S9tKeRkREmTJiAdevWyX0shVdwY6Khojwg\nISFEXl5Eci5PyMEhb37n86n/w4dsy6iQB/n51CA0lDIFghrfW+H/rZKgCqU9y/jnn3/IxcWlyt+n\nstcaMuZKUo8ZAwB88glQUgK8rbTEwaGKSIiw5W0WVWXE28gIQ6ytsTgujm0pjHLr1i2UlJRg0KBB\n7z1vaGiI3r17459//sG3336LnTt3wtfXF/n5+Thy5AgeP34MQFo0599//8Xly5cREhKCmJgY5Obm\n4uTJk7B8e6ps/vz5iI2NRVRUFGJjY8Hn8/HLL7/A0NAQQUFBsLOzQ35+PvLy8mDL8t6ScixgMgGP\n979NaB8fttUojNmXZ6OpVVNM9JnIthQOBriSnQ1dDQ18+k4JR2VjuasrvCIiMMnODt4MBt7xljFz\n+oqWqGdpT0WiPo4BkOZO8vMD1q0D3uZPV2dS81Ox995eGOsaY5T3KOhpMVvukUPxbElOxkx7e6Uu\nkmOhrY1fXF0REBOD/1q1YkxrbT7QmeLd0p4fOofalvZMSEjAoEGDsH79ehQXF5eX9iyDiCosJaoM\nqM9SEgA0agS4uQFXrrCtRCFsv7Mdo71Ho7Vta+y/v59tORx15GlhIe7l52O4jQ3bUqplQsOGKBSL\ncTQtjW0pjKAKpT0ViXo5BqDexDQUCgqx++5uzOo4Cws7L8Sam2sgFAvZlsVRB7by+ZhiZwc9BdRc\nqCuaPB62NWqEH1+9QoFYzLacOvNuac/Lly9DKBQiPj4eX3/9dY1Le4aHh0MoFFZa2jM9PR0AwOfz\nceXtl9h3S3tWBhGhpKQEQqEQRITS0lIIBIK6//IVoPzvwJoydCgQGAioeSDOn1F/ws/JDx4WHvB1\n9IW7hTv+esgd11VVsoRCHEtLw3dKdkS1KjqZmqKbmRlWJCSwLYURlL2053///QcDAwP06dMHSUlJ\n0NfXR8+ePeXyWqhuoZ6qdA8cCPTtC3z7reJEKRCxRIwmO5pgf//98HPyAwBcj7uOyRcm4+m0p9DU\n0GRZIUdNWZuYiEeFhTiogPPwTJJaWooWkZG41bo1GhsYVNmXK9SjOOpvoZ6qUPPlpAsvLsBczxyf\nOH5S/py/iz+sDa1x6skpFpWxy+zZwLJlgKp99oiIsJ2lmgt1paGuLuY7OWFmbCz3oa9GqKdj6NMH\niI4G1GSK+yEbbm/AXN+5701heTweFnZeiBUhKyAh5TzpIE8iI4Hjx6WriCNHSkNaVIUz6elw1tOD\nj7Ex21JqxQx7e8SVlOB8ZibbUjgYQj0dg64u8PXXapki4w7/DhJyEzC46eCPrvXy6AVtDW2cf36e\nBWXsQQR8/710tnD9urSg32efAW/3+JSezUoc0CYLOhoa2OrhgdmxsShR0uOXHDVDPR0D8L/lJDWb\n3m4M24iZHWZCS+PjEBQej4dFXRZhZcjKejWtP38eyMgAxo0D9PWBY8cAf3+gY0fg6VO21VXNnbw8\n8AUC9LeyYltKnehuYQFvIyOsT0piWwoHA6ivY/D1BYRC4O5dtpUwRmJuIq68vIIJbSZU2mdAkwEo\nFBbin1f1o9ypUAj8+KM0prEsEamGBrByJbB4sdRBXL3KqsQq2cLnY7q9PbSU7Bx7bdjo4YHNyclI\nVKV1PI4KUV/HwONJI6EPHmRbCWNsCd+Csa3GwkTXpNI+GjwN/OT3E1bcWKFAZeyxZw/g6AhUdGpv\n7FjpvsOIEcDevQqXVi0ppaW4mJmJ8UpSc6GuuOjpYbq9Pb5/+ZJtKRx1RD2Pq5YRGwt06gTw+Sqf\nIiOvNA+uW1xxf/J9OJk6VdlXJBHBc7sn9vffjy7OXRSkUPHk5gKensDly4C3d+X9nj+XnkcYMgRY\ntUo6o1AGFsfFIVskwvZGjdiWwhjFYjG87tzBPk9PdPugNgF3XFVxcMdVq8LDQ5om4/JltpXUmT/u\n/YHu7t2rdQoAoKWhhQV+C7AyZKUClLHH6tVA795VOwVA6jzCwoDQUOmZhKIixeirimKxGLtSUpSu\n5kJd0dfUxEZ3d8yIjYWQ24hWWdTbMQBqEdMgkoiwJXwL5nScI/M9o71H42n6U9zh35GjMvZITAR2\n7waWL5etv5WVdK9BT09aIryCwFKFciQtDe2MjeFZTVCYKjLQygoNdXTwW0oK21LkQn0o7cl60Z3a\nNNSk4EdmJpGJCVF2tuz3KBnHHh6jzvs61/i+rWFbqf/R/nJQxD7ffEO0eHHN75NIiJYuJXJ2JmKr\nFo5EIqEWERF0JTOTHQEK4ElBAVmFhtKb0tLy52r0f8sS+/fvp+bNm5OBgQHZ2trSd999Rzk5OeXX\nb9y4QQ4ODlRUVERERAKBgPT19elhHd9M169fJwcHhyr7rF27lpo3b07Gxsbk6upK69atq7RvZa81\n6l2hnsqwsJAeaj+lmhHBRFQe0FZTJrSZgHB+OB6+eSgHZewRGSn99v82BU2N4PGAJUukp5a6dWNn\nlfF6Tg7ERPi8lvWBVQEvQ0OMtrHBglev2JYiM8pe2hMADh06hJycHAQFBWH79u04fvy4fAaSxXsw\n2QIDA3t6eno+8/DwiFm9evW8yvpFRES009TUFJ0+fXrQh9dQ028eZ84QdelSs3uUhJCEEPLY6kEi\nsahW968NXUvDTg1jWBV7SCREn35KtHt33W2FhBDZ2BD99lvdbdWEvtHRtIvPV+ygLJArFFLDmzcp\nPDeXiJR7xqBKpT3LmDFjBgUEBFR4rbLXGjLOGBTqFEQikaa7u3tsXFyci0Ag0Pb29n7w5MkTr4r6\nde3a9VqfPn0unDp1avBHomv6BistJbK0JIqLq9l9SsCAYwNoR8SOWt+fV5JHVmut6Fn6MwZVscfZ\ns0TNmhEJhczYi40l8vQkmj2bSFQ731sjYoqKyCo0lAoVMZgScCA1ldpFRpJYIlFqxxAYGEhaWlok\nFos/ujZmzBgaPnw4EREdOHCA/Pz8yq/Fx8cTj8crvy8oKIh8fHwo960zfPbsWfmH/KxZs6h///6U\nnZ1N+fn51LdvX1qwYAEREQUHB1e7lPQuEomEWrVqRbt27arwel0dg0KXkiIiItp7eHjEuri4xGtr\nawuHDRt27OzZs/0/7Ldt27aAIUOGnLK2tmYmqYGOjkqmyIjJjEFoYijGeI+ptQ1jXWMEtA/A6pur\nGVTGDhUFs9UVd3fg9m3gwQNg0CCgoIAZu5WxLTkZExo2hIFm/ciAO8rGBpo8HvbLsNvP4zHTakN1\npT0zMjIA1Ky0p0QigaenJ2xtbUEkLe25ceNGmJmZwcjICAsWLMCxY8cqtFMdS5cuBSDdCJcHCi3t\nyefz7R0dHctj5h0cHJLDw8M7fNjn7Nmz/a9du9btzp077Xg8XoWvWNkLAwD+/v7w9/evevBRo6Q5\nE376qfbvHgWzJXwLJvlMgqGOYZ3sBLQPgMc2D8TnxMPFzIUZcSxQVTBbXTA3B4KCgClTgC5dpCk2\n5HGKNFckwqE3bxDdrh3zxpUUDR4P2xs1Qp+H1e9z1fCzkVFUqbTn9u3bcfjwYYSEhJTXiaiM4OBg\nBAcH13gMhS4lnTp1avCECRP2lD0+dOjQN9OnT9/2bp8hQ4acDAsL60BEGDNmzAFGlpKIpIvTHh5E\n4eE1v5cFMosyyWy1GaXkpTBib/6/8+m7C98xYosNcnKk+wEPHshvDImEaNUqIgcHovv3mbe/KSmJ\nhj1+zLxhFWDSs2dKvZSUk5NDhoaGdOLEifeez8/PpwYNGtDevXuJSHpq6d2lpLi4uPeWkt4lLS2N\n/P39afHixSSRSMjAwIBSUir+f5Z1KWnv3r3k6OhIcdUsi1f2WkMZl5Ls7e35SUlJjmWPk5KSHB0c\nHJLf7XP37l2fYcOGHXN1dY07ffr04KlTp/527ty5fnUenMdTqZiGXZG70N+zPxoaN2TE3uyOs3Hs\n0TGk5Kvm2XJZg9nqAo8HLFgAbNwIfPEFcOECc7bFRNianKySNReYYKWbG9sSqkQVSnv+9ddfWLhw\nIa5cuQIXF5c6/85VIov3YKoJhUItNze3l3FxcS6lpaU6lW0+l7WxY8fuZ+RUUhkvXxJZWxMJBLW7\nX0GUikrJboMdRb2OYtTurKBZNOfyHEZtKoKEBCILC6LkZMWNefs2UcOGRJs3S2cSdeVMejp1uHu3\n7oZUmFr/3yqQvXv3UvPmzUlfX7/85NC7cQwHDhygzp3/F1MUFxdHGhoa5TOGq1evUsuWLcnIyIis\nrKzom2++ocLCQiKSnkr66aefyM3NjUxMTMjLy4u2bdtWbuvbb78lS0tLMjc3r/BUkqurK+no6JCR\nkVF5++67ilcBKnutoYynkogIly5d6tW4cePn7u7usatWrVpARNi5c+fknTt3Tv6wL+OOgYjok0+I\nzp2r/f0K4MD9A/TFwS8Yt5ucm0zmq80prSCNcdvypLbBbHUlLo6oaVOiadPqfgrK//59OvrmDSO6\nVBVVcAzqQl0dg3on0auIXbuk0VEnTjAriiGICK12tcKaz9egpwfzhb6nXJgCSwNLrOymGnmUIiOB\nfv2kifDYKHCWmwt89ZX0FNSxY4BJ5YltK+VBQQG+fPgQcR06QFtZMvixAJdET3FwSfRqytdfS8Nd\nc3LYVlIhV+OuQiQRoYd7D7nYn/fJPOyK3IWcEuX8/d+F3qnMxlbVS1NT4OJFwMkJ8POT5miqKVuS\nkzHNzq5eOwUO1aL+vVPNzaU7iydPsq2kQjbc3oA5Hee8V8+ZSVzNXdGncR9sj9guF/tM8m5lNjbR\n1gZ+/x0YM0Za/ykyUvZ70wQC/J2RgUl2dvITyMHBNLKsNylbQ13XKv/+m6hzzZPSyZtHbx6RzTob\nKhYWy3Wcp+lPyXqtNeWX5st1nLogEEgjki9dYlvJ+5w5Q2RlRfR//ydb/2VxcTTxmXpEndcVc3Nz\nAsA1BTRzc/MK/wZQxuOqSkOvXtJiwHFxbCt5j01hmzCt3TToaenJdZwmVk3g7+KPXZG75DpOXZBX\nMFtdGTA/U8c3AAAgAElEQVRAGgwXECCNwK5qybxUIsHvKSn19ojqh2RlZZV/8JSIxWgUFoZLGRms\nf9FUx5aVlVWnv5VMjuHKlSvd6zSKslGWIuPwYbaVlPOm4A1OPz2NKW2nKGS8hZ0XYsPtDSgWFitk\nvJqQmwv88guwfr1yBqn7+EjTaBw+DEyeLE3VUREn0tLQwtAQzQzrFrmujuhqaGCzhwdmxsailCvo\no3TI5Bh69uwZ5OHhEbt27dofMzIyrOQtSiGMHi0NdqvqK58C+S3yNwxtNhTWhrKF3tcVb1tvtLVr\ni3339ylkvJqgiGC2uuLoKK0Ix+dLtX54loGIsKkeB7TJQm9LS3gaGGBzcnL1nTkUiyzTkuvXr/sP\nGzbsqK6ubomOjk7psGHDjl6/ft2frWkSmDgPLZEQNWpEFBZWd1t1pEhQRNZrrRWeATUsKYycNjlR\nqai0+s4Kgo1gtrogFBIFBBB5eRG9evW/529kZ1OjsDASMxEdp8bEFBWRRUgIJZeUsC2lXgAm9xj8\n/f2Djx49OjwpKclxxYoViyIjI9t269btmpeX19PNmzfPys7OVr2KI0qUIuNQ9CF0cOgATytPhY7b\nwaEDGls2xuFo5VlSW7gQmDZNPkns5IGWFrB1K/Ddd0CnTtIlJgDYwudjpoMDNJRxLUyJ8NDXxxQ7\nO/zw8iXbUjjeRRbv8WGTSCS8f/7553M/P78QHo8nMTAwKBw9evSfUVFRLWtjr6YNTEVQvnolPWJS\nyt43ZrFETJ7bPOl63HVWxg+OCyaPrR4kFDNU4KAO3LkjTUORl8e2ktpx4YL07bTtUClZhIRQfj2p\nuVBXCkQicrx1i/5T4fK7qgLkeSrp0qVLvbdu3TojLCyso42NzZuRI0f+9d9//33q4+Nz97fffpvK\nqOeSJ66uQJMmQGAgaxIuxVyCgbYBPnX+lJXxuzh3gY2hDU4+Zjeug5QgmK2u9OkD/Psv8NOPPHid\n8YKhRv2ouVBXDDU1sd7dHQExMRApyZ5fvUcW70FESElJabh8+fJFzs7O8TweT9K5c+cbR48eHSYQ\nCLSJpAnypk2btt3W1jZVVpu1bWAy58ru3USDBzNnr4Z0PdCVDkcdZm18IqLAmEBqtqMZiSUfpw5W\nFExXZmOLfJGIzP8Op+atxTRmDKuTUZVCIpFQ1/v3abuqbC6pKGAyid7AgQP/T1tbW2BiYpI7derU\nHY8ePWpWUb+bN2924vF4Ells1qUx6hiys4lMTIiyspizKSP3Uu6Rw0YHEojYzfYqkUjIZ5cPnXl6\nhpXxlTWYrTZsT06mQQ8fUkEBUf/+0vrUmZlsq1INHhYUkHVoKKUrefZjVUZWxyDTUlJMTEyjLVu2\nzOTz+fY7duyY1qxZs8cV9WvRosXDa9eudWNqNqMQzMyA7t1ZSZGxMWwjAtoHQFuz6ipM8obH42Fh\n54VYcWNFmeNVKMoazFZTJETYkpyMWQ4OMDQETp8G2rYFOnYEYmLYVqf8NDc0xPAGDbDw1Su2pXDI\n4j3i4+OdS0tLdSq6JhAItBMSEpxkscNUA9Ppe8+eJXqnKpMiSMpNIvPV5pRdrBwbbmKJmJrtaEaB\nMYEKHVcRldkUxcWMDGpz5w5JPjiiunOn9He8cYMlYSpEtlBINjdvUqSqnkBQcsDkjMHNze3VgwcP\nWlV0LSoqytvV1VW5ckvUlJ49pXmdFfhNZVvENozyHgUzPTOFjVkVGjwNVmYNqhDMJiub3wa0fZgA\ncfJk4OBBYPBgpTgdrdSYaWlhpasrAmJiIGFh9sohRSbHQFXk7xYKhdo8Hk+1/4I6OsDQoQpLkVEg\nKMDee3sxq8MshYwnK183+xpvCt/gRsINhYyXmAjs3g0sX66Q4eTK48JCPCwsxNAGDSq83r07cP06\n8PPPwJIlShNwr5SMs7WFiAiH37xhW0q9RauyC9nZ2ebZ2dnmZU4hOTnZwcrKKuPdPkVFRQYHDx4c\nbWtr+1reQuXOqFHAyJHA4sVyT9Cz7/4+dHXtCldzV7mOU1M0NTSxwG8BVoSswKcu8j8+q2rBbFWx\nNTkZ39nZQbeKmgvNmgFhYUD//tI9h337AD355ktUSTR4PGxr1AgDHz3CACsrmGhV+jHFIS8qW2Na\nsmTJUh6PJ5GlLVu27GdZ1q2YapBHiUCJhKhxY2mxXzkiEovIdbMr3Uq8JddxakupqJScNjlRWJJ8\nU4WUBbPlK2/mb5nJEAjILCSEXst4NrWoiOirr6RVZtNUq8qqQhn39CnNjY1lW4ZagbqW9nzw4EGr\nsn2Fb7/9dt+iRYtWuLm5vbcIr6urW9qsWbPHLVu2jJa3A3uXOpX2rIoVK4CUFOC335i3/ZbTT05j\nw+0NuDX+ltzGqCs7Inbg8svLODf8nFzsEwFdu0onaBMnymUIhfJrQgJeFBdjf5MmMt8jkQCLFgHH\nj0srxNXg1nrDG4EAze/cwY1WreDFZahlBFlLe8r0DX3//v1j09PTrWTpq4gGeRUVj4sjsrSUa1SS\n7x++dOrxKbnZZ4IiQRE1XN+QHqTK56iQugSzEREJxGKyv3WL7tdy6rNvH1GDBkRXrzIsTE3YlJRE\nnz948NFJL47aASZPJY0dO/bAh/sLaomLi3Qh+NIluZi/nXQbrwteY0CTAXKxzxT62vqY6zsXq0JX\nMW5bKAR+/FFa5EYdlo5PZ2TAQ18frYyManX/uHHAsWPA8OHSPQeO95lmZ4eU0lKcyVD/jx9lotKl\npK5du17//fffv2vSpMmzrl27Xq/s5BER8Xg8HikysE1uS0kA8Mcf0txJp08zbvqrk1+hs1NnzOgw\ng3HbTFMgKIDbFjfcGHcDTayYW+f47TfgzBngyhXlLMJTUzreu4f5Tk4YYFW3MiXPn0tzLQ0ZAqxa\nBVSxh13vuJadjW+fP8eTdu1goMnln6oLsi4lVfr2e/dmIuIREU8ikWh82MquMSWcdYYMkWZCq2Np\nvA+Jy47D9bjrGNeK5cr2MmKkY4QZHWbg19BfGbOp7JXZakpYXh7SBAL0tbSssy1PT+mJpdBQaXHB\noiIGBKoJ3czN0d7YGGuTktiWUm+odMagzMh1xgBIYxq6dgWmMFdmc1bQLOhq6WLN52sYsylvckpy\n4L7VHZETIxk5WrtgAfDmjfosmQx/8gTtjY0x29GRMZulpcD48dLjrGfPAra2jJlWaRJLStDm7l1E\n+vjAhTvjW2vqPGOo1zBcwCenJAcHow4ioH0AYzYVgZmeGaa0nYI1N+vuzNQpmA0AkktLcTkrC982\nbMioXV1d6Vuvd29pjqVHjxg1r7I46elhloMD5sTGsi2lXiCTY/j7778H7N+/v3wNJCEhwbljx45h\nRkZGBYMHDz5dUFBQu503ZaVHDyA2FmCoqtTuu7vRu1FvOJioXv3fWR1m4cTjE+Dn8etkR52C2QDg\nNz4fo2xsYCqHHXQeTxodvXIl0K0bcPky40OoJN87OiKqoAD/MLzMy/ExMjmGlStXLkxLSyuP9Z8z\nZ85GPp9vP2nSpN0hISGdlyxZskx+EllAW5uxFBlCsRDbIrZhru9cBoQpHmtDa4xtNRbrb6+vtY3I\nSODqVelpJHWgSCzGntRUBDjI19GPHCk9AzFmDLBzp1yHUgn0NDSwycMDM2JjIZBI2Jaj3shyptXc\n3DwrMDCwJxGhsLDQQE9Pr/j48eNfExH27NkzwdXV9ZUsdphqkFccw7tERBC5u0sjouvA4ajD1PVA\nV4ZEsQM/j0/mq83pTcGbGt8rkUhrEuzezbwuttjN51Pf6GiFjRcTIw3Knz2bqL5XC5VIJNQzKorW\nJyayLUUlAZNxDCUlJXr6+vrFAHDr1q1OQqFQu0ePHpcBoHHjxi9SUlLsZHVEQUFBPZs0afKsUaNG\nMWvWrJn34fWzZ8/29/b2jmrduvV9Hx+fu6zVd2jbVjpzKKvuXguICBvDNmKO7xwGhSkeO2M7DGs+\nDJvCNtX43vPngYwM6Xl9dYCIyrOoKgoPD+nb8P59YNAgoKBAYUMrHTweD1s8PPBrYiJSS0vZlqO+\nyOI9mjRp8nT58uWLiAgBAQFb27dvH1527eTJk0MaNGjwRhY7IpFI093dPTYuLs5FIBBoe3t7P3jy\n5InXu30KCgoMy36Ojo5u4e7uHvuhHShixkBEtHIl0ZQptb79etx18tzmyWrJTKaIy44jizUWlFUk\ne6U7darMVsaVzExqHhHBSiRuaSnR2LFErVsT1fcKmD/GxtLoJ0/YlqFygMkZw5QpU3YuW7ZsiY+P\nz90dO3ZMGz9+/N6ya2FhYR2bNm36RBY7ERER7T08PGJdXFzitbW1hcOGDTt29uzZ/u/2MTQ0LCz7\nuaCgwIjViOuRI6WV3Wr5zWTD7Q2Y3XE2NHiqf/jLxcwF/Tz7YVvENpnvUZfKbO+yhc/HrApqLigC\nHR3pUd+vvgJ8fYEHDxQuQWlY5OyMqzk5uJWby7YUtUSmIxUzZ87cYmVllXH79m3fmTNnbhk9evTB\nsmt5eXkm48aN2y+LHT6fb+/o6FgepeLg4JAcHh7e4cN+f//994AFCxb8mpqa2vDKlSvdK7K1dOnS\n8p/9/f3h7+8vi4Sa4ewMNG8uTZExcGCNbn2e8RwR/AicGHKCeV0sscBvAfz2+WF2x9kw1jWusm9Z\nMNvly+oRzAYAL4qKEJGXh5NNm7KmgceTxoN4eEhrPOzfL42Yrm8Ya2lhjZsbpsfE4I6PDzTV5U3G\nMMHBwQgODq75jbJMK5hqp06dGjxhwoQ9ZY8PHTr0zfTp07dV1v/GjRudGzdu/PzD56GopSQioj/+\nIBowoMa3TT4/mX6+/rMcBLHL0JNDaW3o2mr7zZ9PNG6cAgQpkGkvXtDCV6/YllHO7dvS1OVbtrCt\nhB0kEgn53btHO/l8tqWoDJBxKanGh7DT0tIalJSUfBR66OTklFjdvfb29vykpKTyMNGkpCRHBweH\n5Mr6d+7cOUQkEmllZmZaWlpaZtZUKyMMGQLMmQNkZgIypj5IL0zH8cfH8WzaMzmLUzw/df4JPQ73\nwPT206GvrV9hn7JgtmiFJmOXLzkiEY68eYNH7dqxLaWcjh2BmzeBL7+URkpv2qQeiQllhfe2oE+P\nqCh8ZW0NC21ttiWpDTItfufm5pqOHTv2gL6+frGtre1rFxeX+HebrDWf27ZtGxkTE9MoPj7eRSAQ\n6Bw/fnxov3793kv6//LlS3d6G7J97969NgDAmlMAAFNToFcv4ITsS0I7I3disNdg2BjZyFEYO7S0\naYkO9h2w9/7eSvuoWzAbAOxNTUUvCwvY6eqyLeU9XF2lzuH5c6BfPyAvj21FiqWVkRGGWFtjcZxq\nl51XNmT6fjF9+vTtp0+fHjxhwoQ/mjdv/khXV7dWu7FaWlqi7du3T+/Ro8dlsVisOX78+L1eXl5P\nd+3aNRkAJk+evOv06dODDx48OFpbW1toZGRUcOzYsWG1GYtRRo2ShqF+9121XUtEJdhxZweujr6q\nAGHssLDzQgw+MRiTfCZBR1PnvWtlwWwvXrAkTg6IiLCNz8cJFvcWqsLMTFrsZ/p0wM8PuHABcHJi\nW5XiWO7qCq+ICEyys4N3LdOfc3yALOtNVlZW6du2bZsuS19FNChyj4FIeu6yQQNppFE17L23l3oe\n7qkAUezS/VB32nN3z3vPqWMwGxHR6bQ06nT3LtsyqkUiIVq/nsjOjujO5Uy5FpxSNnby+dT53j2u\noE81gMnjqgDQpEkT9VswlxVtbWkllWoS6xERNt7eqLLpL2rCos6LsDp0NUQSUflz6hbMVoaiA9pq\nC48HzJ0LbFyYiE79xfiq9xRQPTnOOaFhQxSKxTialsa2FLVAJscwdOjQ4+fPn+8rbzFKzahR0txJ\nVHm678svL0NTQxOfuX6mQGHs0Nm5M+yM7XD80XEA6leZrYx7+fmILynBIGtrtqXIhPjNaxy91xSf\njpuLs2Gr0bXfAojSXrMtS+5ovt2I/vHVKxSIxWzLUXlk+hfu0aPH5ZkzZ27Jy8sz6dOnz0ULC4uP\n0ht269btGvPylIg2baQ5kW/dAj75pMIuG29vxJyOc1gJfmKDRV0WYfbl2RjeYjj27NFQu2A2ANiS\nnIzp9vbQUoG/KRUUIGB+SxQ4WePSz38gepIQfp8uQpv+GxFxdBL0XDzYlihXOpmaopuZGVYkJGC1\nmxvbclQbWdabeDyepKqmoaEhlsUOUw2K3mMoY9UqosmTK7wU9TqKGq5vSKWi+rOuK5FIqO3utnQw\n/CzZ2BA9eMC2ImZJLS0ls5AQyhQI2JZSPQIB/Trek1r+ZE45RdnlTz+PLSEjyzhybrOSch7dY1Gg\nYkgpKSHL0FB6XljIthSlBDLuMchUwS04ONi/uj7+/v7BdXVSsiL3Cm6VkZgItG4NpKRIZw/vMPbv\nsWhs2Rg/df5J8bpY5Oyzs5g8KxO97cZh3z7l/1ZdE5bExSFNKMTvjRuzLaVqiHBohj8WGUfg1vdP\nYW/h8t7l1NditPR5BVj+g4e7vWDbsSs7OhXE+qQkXMvOxsUWLerN7F1WZK3gxpX2rCndukkP6Q8e\nXP5Uan4qmv7WFC9nvISFvgU7ulgiPkECj2Z52Bd0F6P91GdvpUQigUtYGK57e8PL0JBtOVXy78/f\nYKToOK5NuoVmLhUH4OXkEFq1e4oszSjc3ayDRj0HV9hPHRBIJGgZGYl1bm7oa2XFthylQi6lPTMy\nMqwuXLjw5Z9//jkmMzPTEgCKi4v1xWKxZm2FqhwVlP3cfmc7RrYYWe+cAgAsXqSB/t8kY+fzxVDF\nLxmVcSwtDa2MjJTeKURtX4wRwmM48fXJSp0CAJiZ8fA0uimc9ZujxVR93Dn6hwJVKhYdDQ1s9fDA\nrNhYlHAFfWqHLOtNEomEN3fu3PU6OjqlZXsKd+/ebUNE6N69++Vly5b9LIsdphrY2mMgIsrNJTI1\nJcrIICKigtICslprRTGZ1cc4qBt37khz9eTkiqjR1kZ07dU1tiUxgkQiIe87dygwM5NtKVWScHw3\n2X+vQcf+lT1ZkkBA5NflAWnbh1DQ9tVyVMc+Ax4+pOXx8WzLUCrAZBzDr7/+umDHjh3TlixZsiw8\nPLwDvTMV6du37/mLFy/Wn/yOJibSFBnHpcc0/4z6E35OfvCwUO8THx9CBHz/PbBsGWBqoomfOv+E\nFSEr2JbFCDdyc1EqkaC7uTnbUiolOzgQvUK/w5x2MzD0sxky36etDfx33Ru925mgzy898NeKhXJU\nyS4b3d2xKSkJiSUlbEtRPWTxHq6urq9Wrlz5ExFBKBRq8Xg8SdmM4dKlS70sLCwyZbHDVAObMwYi\naeWZjh1JJBaRx1YPuhF/g109LHD2LFGzZkRCofSxQCQg503OdCvxFrvCGGDAw4f0mxJXwil+eJ+6\nTNSmWTtrnvW3DImEaOLEh6Rp/oI2zp3OoDrlYklcHH316BHbMpQGMDlj4PP59r6+vhXWuNTR0REU\nFhYq90Is03zxBRAXhwvBu2GuZw4/Jz+2FSmUioLZtDW1Me+TeVgZspJdcXXkVXExQnJzMdrWlm0p\nFSLhJ2PM+k/QoFErbJh0utZ2eDxg9+7mmP+dBD/smocFkyZUGbypqsxzdEREfj6Csj4KveKoApkc\ng52dXcrDhw9bVHQtOjq6pazZVdUGLS1g+HBsuLEac33n1rsjcXv2SJO0fRjMNq71ONx/fR/3U++z\nI4wBtvP5GG9rC0NNJTxPkZuLH+a1RqpbAxyafYORyoArVnpiw3IR1v21At+OHAsSiaq/SYXQ19TE\nfk9PfPvsGVcjuibIMq348ccf11haWmaEhIT4iUQizbKlpGfPnnna29snL126dIksdphqYHspiYgi\nrh4kp+81SShSgeAnBsnJoSqD2Tbc2kBDTgxRrCiGyBUKySIkhBKKi9mW8jElJbTpGw/yWmROmYUZ\njJv/63AKaemnU58Bo0lUXMS4fbZZEhdH3e7fJ1E9T7IHGZeSZPogLiwsNPDz8wvh8XgSFxeXOB6P\nJ3Fzc3upra0t+PTTT4NLSkp0ZbHDVFMGxzDs5DDaMMCGKCSEbSkKpbrKbAWlBdRgXQN6nPZYcaIY\nYktSknKuR4vFdGJCJ7JfqE/xGS/lNkxQYBZp66dRx54TqCQ3S27jsIFIIiH/+/fpl7g4tqWwiqyO\nQeYAN5FIpHX06NHhQUFBPdPS0hpYWlpm9urVK3DkyJF/aWlpKXT+yWqAG4DE3ES03tUacZIZMHnF\nl5YrqweUBX5HR1ddhGdVyCo8zXiKQwOrzkarTEiI0DgiAgebNEEnU1O25bxHyA9DMUjnDP6ZFIJW\nzh+VSGeU8PAi+H+WD9f2KxFx7EcYNVD+rLKyklJaCp+7d3GsaVN8ambGthxWYDTyubi4WP/u3bs+\nqampDQGgYcOGqT4+Pnf19fWLGdBaY9h2DN9f+R4EwoamswFvb4DPB/Q+qnaqdowaJa0Y9ssvVffL\nLcmF+1Z3hE8Ih7uFu2LE1ZHzGRn4JSEBEW3aKNWe0ZN1P6Jr1kYcHnYCX3gPUsiYz58J0bbjG5g1\n24V7h4fD2lU5CxTVhqCsLEx4/hz3fXxgraNT/Q1qhqyOocrpRHFxsV5AQMBWPT294g8T5xkYGBTO\nmTNnQ2lpqY4sUxMmG1hcSsotySWLNRYUnx0vfaJbN6KTJ1nToyjKgtny82Xrv+jaIpp4bqJ8RTFI\nt/v36fDr12zLeA/+n9vJea4m/Xltk8LHTkoUk1WDl2Ths57iH95U+PjyZN7Ll9QrKorE9XC/AUzs\nMXz++ef/aGhoiAcOHPh/u3fvnhgUFNQjMDCw5+7duyf279//bw0NDXHPnj0DZRmIycamY9hwawMN\nPTn0f0/s30/Urx9rehRBbSqzpRemk/lqc0rKTZKbLqaIzs8nu5s3qVQsZltKOblBZ8l7miatPDmD\nNQ2ZmUROjs/IsPleig69wJoOphGIxeR79y6tTUhgW4rCqbNjOHHixFeampqi06dPD6qsz6lTpwZr\namqKTp06NViWwZhqbDkGoVhITpucKCI54n9P5uVJU2Skp7OiSRF8GMwmK3Mvz6UZgex9sMnK+GfP\nlCp1QundCPp8vDZN3t2P9VKV+flEzZs8It1Gp+nGxYOsamGS+OJisg4Npdu5uWxLUSh1dgwDBw78\nv2HDhh2tzsDQoUOPDRo06LQsgzHV2HIMxx4eo877On98YcQIom3bFC9IAQgERJ6e0mDvmpKSl0Lm\nq83pdb5yLdG8S9rbmgtpSlIfWfLqFY0eoU99N7QlobiGnlhOlJQQfdLuIWk7/Ut//7WZbTmMcSY9\nnZxv36YsVai3wRCyOoZKI2Tu37/fuk+fPher26P48ssvL9y9e9dHhn0PlYaIsOH2BszxnfPxxQoy\nrqoLlQWzyUJD44YY0WIENoVtYl4YQ+xOTcVga2vl2IjMzMSieW3x3KsBjgX8By0N5aiRqqsL/He7\nOXp6NsCQub74Y/tStiUxwgArK/S3tMT458/LvnByvKVSx5Cenm7t7OycUJ0BJyenxLS0tAbMylI+\nbibdRHZJNvo2rqD09eefS89yPn+ueGFyJDdXegJp3TppCoXa8OMnP2LPvT3IKla+lAQCiQS/8fmY\nWdXZW0VRVISd37XDCS/C+dl3YKBtwLai99DUBM5eboHR/gb4bunXWLWigi9IKshad3cklJRgR0oK\n21KUikodQ1FRkYGurm61MeQ6OjqCkpIStT+rueH2BszuOBuaGhWkSnibIgOHDytemBxZvRro3Vt6\nIre2OJk6YUCTAdgavpU5YQxxMj0dTQwM0MLIiF0hIhHOTfbHMs/XCJoRAWtDa3b1VAKPB+w92hxz\nR2hiyboZmPnDJJX/pq2roYHjzZphWXw87uXnsy1HaahyrpqcnOxgZWWVUVUfPp+vBF+35EtMZgxC\nE0NxeGAVH/yjRwMDB0rzUGvUPYcN2yQmSuP2oqPrbmv+J/PRaV8nzPGdAxNdk7obZAAiwubkZPzs\n7My2EITPHILxzg9wcUIw3C2VP3376q2eaNAgDvN+XYY3+WNx5Ld90KjoC5OK4KGvj22NGmHokye4\n6+MDEy3lWMJjk0oD3DQ0NGpU+kgikSjs01DRAW7TL02HqZ4pVnarInMoEdCyJbBjB9Cli8K0yQtZ\ng9lkZcTpEfC28cY8v3nMGKwjt3JzMfrZM7xo3x4aLAa0xSybgS4lv2PPsCP40vsr1nTUhkO7+Bg/\nWwddBs1B4P4/oK2tW/1NSszk58+RJxbjiJeXUgU5MomsAW6VusZ9+/Z9W4PBVHs+WQVZxVn46+Ff\neDz1cdUdebz/bUKruGOIjASuXgVevGDO5k+df8LnBz9HQIcApVg/35ycjBn29qw6hbSdG9Ar73cs\n67NK5ZwCAIyabA9LqwwM/GYTfIsn479DW2BooFzpRGrCZg8PtL93D3tfv8aEhg3ZlsMushxdUrYG\nBR5XXXVjFY05M0a2zklJRObmRMqYnVNGahPMJisDjg2gLWGyl6GUFwnFxWQREkJ5NQ3MYJCCMyeo\n3VRtWnRyKmsamOLWtXzS039DHr2nUGYWn205deJJQQFZhYbSw4ICtqXIBTBZqKe+IhALsC1iW8VH\nVCvCwQFo0wY4f16+wuTI+fNARgYwbhzzthd2Xoi1N9eiVMRuXvwdfD5G29rCmKW1ZNGtUAz9eySa\ntu6OXwZvZ0UDk/h2NcKdW6Z4c+NnNBuyCfwU1T2d52VoiHXu7vj68WMUisVsy2ENhTuGoKCgnk2a\nNHnWqFGjmDVr1ny04PzXX3+N9Pb2jmrZsmX0J598cjM6OrqlojWWcfThUTRr0AwtbWogYfRo4OBB\n+YmSIxVVZmOStnZt0cKmBf6M+pN54zJSKBZj7+vXCGDpiCo9e4apW7pD6N0Ce8adUZu17OatdPEw\nqgFE9wLQ7KuTeBEbwbakWjPGxgZtjY0xIyaGbSnsIcu0gqkmEok03d3dY+Pi4lwEAoG2t7f3gydP\nnu7d8sQAACAASURBVHi92+fWrVu+OTk5pkSEwMDAnh06dAj70A4UsJQkkUio5e8tKTAmsGY35udL\nU2SkpclHmBzZsYPoiy+ky0nyIiQhhFw3u7IW1fs7n08DHj5kZWxKSaHl/c2p9UonyivJY0eDnHnz\nWkKONjFk0GYH3bkfxLacWpMvElHjsDA6pGSJFesKlHEpKSIior2Hh0esi4tLvLa2tnDYsGHHzp49\n2//dPr6+vrdNTU1zAaBDhw7hycnJrCSEvxp3FSKJCD3ce9TsRiMj4MsvgWPH5CNMTjARzCYLfk5+\ncDJ1wtGHR+U3SCVIiLAlORkzHVh4S+Xl4cCUjtjbmnAxIAzGusaK16AAGtjw8PC5B1wyu8FvRBb+\n+e8I25JqhZGmJk40a4bZsbF4UVTEthyFo9BFVj6fb+/o6JhU9tjBwSE5PDy80soje/fuHd+7d+9L\nFV1bunRp+c/+/v7w9/dnUKk0oG1Oxzm1m+qPGgUsXgwEBDCqSZ4wEcwmK4u6LEJAYABGthzJSN1i\nWbmSnQ1dDQ18quhCPAIBLn/7KeZ5pyP4u0g0NFbvEy+mpkDk0yb4rJ0YX34bjz83bMOwAarzv1CG\nt5ERlru64usnTxDWpg30VDA+KTg4GMHBwTW/UZZpBVPt1KlTgydMmLCn7PGhQ4e+mT59+raK+l67\ndq2rl5fXk6ysLPMPr0HOS0mP3jwim3U2VCys5ekioVBavODpU2aFyYmEBCILC6LkZMWMJ5FIqP2e\n9nTysWLrWPSMiqL9qakKHZPEYro7ridZLdKh0Lj/FDs2ywgERL07PSRt+xu0df8ytuXUColEQl89\nekRTnz9nWwojQBmXkuzt7flJSUmOZY+TkpIcHRwckj/sFx0d3XLixIl7zp0718/c3DxbkRoBYFPY\nJkxtNxV6WrXM9KGlBYwYoTKJ9RYuBKZNq7pcJ5PweDws6rwIK26sKHP0cudpYSHuFxRgWAPFpvWK\nnz8FfW2uYefgA/jERbXjW2qKtjZwPqQ5hrcyx/c/9sOiLXMU9vdmCh6Phz2engjKysKp9HS25SgO\nWbwHU00oFGq5ubm9jIuLcyktLdWpaPM5ISHByd3dPfb27dsdK7MDOc4YXue/JrPVZpRWUMfN4wcP\niJyciJSo+EtF1LQyG1NIJBLy/t2bzj8/r5Dxpjx/Tj+/eqWQscrI3LCCPOfo0JZrvyp0XGVDIiGa\nO/ox6Zi+oAlLx5NYotz/ExURkZtL1qGh9LKoiG0pdQJMVHCTR7t06VKvxo0bP3d3d49dtWrVAiLC\nzp07J+/cuXMyEWH8+PF/WFhYZLZq1ep+q1at7rdr1y7iI9FydAw/X/+ZJp+fzIyxFi2IgoOZsSUH\n5BnMJgvHHx2nDns6yL0YTaZAQGYhIZSqwJoLRUcP0SdTdOj7k5MUNqays2buC9IxTKJ+c0YqTa2J\nmrAxMZHaRUYqVaW/mqK0joGJJi/HUCQoIuu11vQ0naG9gbVricaPZ8aWHKhtZTamEIlF5LnNk/59\n+a9cx1mTkECjnjyR6xjvIrr6Dw0apUPD/uipkt+O5cm+tXGko/ea/CYNoyKBan37lkgk9GV0NM2J\niWFbSq3hHEMt2BW5i7488iVzBvl8aYoMJZx+1qUyG5P8+eBP6nqgq9zsCyUScrx1iyLzFBM3IHnw\ngAIG6ZP/plZUIixRyJiqxt/7UkhXN52afzOcsouy2JZTIzIEAnK8dYvOZ2SwLaVWyOoYVO/8lZyQ\nkAQbb2/EnI4MFiCxswPatgXOnWPOJkPUpTIbkwxvPhxxOXG4mXhTLvbPpKfDRU8PPsYKiBtITMSG\nBZ/iWltLnJlyHbpaqp1tVF70H9cQV05q4OWpLWj1zVy8zlOdIjmW2to40rQpJjx/juRSdlO7yBPO\nMbzlUswlGGgbwN/Fn1nDSlj2U1HBbLKgramN+Z/Mx8qQKlKa14HNigpoy8rC0Um+2NKRh8Cpt2Cm\nZyb/MVWYLn0tcPMfPWQF/oqWw1bhVZrq5FfyMzXFTHt7DH/yBCJSrVNWssI5hrdsvL0Rc33nMp+7\nZuBAIDQUSEtj1m4dUGQwmyyMbTUW0W+icS/1HqN27+TlgS8QoL+VFaN2P6K4GNdHd8HMDtm4NPkG\nHE0dq7+HA639jHEvwhSSkPloNfQQouLC2ZYkM/OcnKCvoYGl8fFsS5ELnGMAcD/1Pl5kvsDXzb5m\n3riREdCvn9KkyCirzLZ8OdtK/oeuli6+7/Q947OGLXw+AuztoSXPaZFYjIff9sHQ1rE4NvocWti0\nkN9YaohHcz1EPbSBWdS36DQ8FDceB7ItSSY0eDwc8vLC/tRU/JOlfPXM6wrnGABsDNuIGR1mQFtT\nWz4DjBqlNBlXFy4Epk9XXDCbrExsMxGhiaF4nFZNQSQZSSktxaXMTIyXZ8EVIiTPHIc+LrewedBu\ndHP/XH5jqTH2Ltp48MIFTglfoseIVJy99RfbkmTCRkcHh7y8MObZM7wWCNiWwyj13jEk5yXj4ouL\nmOQzSX6DdOsGpKYCT5/KbwwZKKvM9sMPrMqoEEMdQ8zqMAu/hv7KiL3fU1IwwsYGZnKsuZC78mf0\n1jmJ6Z//hBGtR8ttnPqAhZUG7rxojJYFHTB0nAH+CNrKtiSZ6GZujokNG2LkkycQq9F+Q713DNsi\ntmGU9yj5bhZqarKeIoMI+P57YNky6eqWMjKt/TQExQYhNiu2TnaKxWLsSknBDDlOi0r37cbA5PXo\n0mk4fui2WG7j1CeMjHm48aQZ/PXcMX1yc6w69jPbkmRisYsLRET4NTGRbSmMUa8dQ4GgAHvv7cXM\nDjPlP9ioUcBffwESifzHqgB5VmZjChNdE0xrPw2rQ1fXyc6RtDS0MzZGYwP51JaWXLyAcddmwqxd\nZ2wZtEdtiu0oA7q6wMV7LTHIyQrLZ32JWTtnlMUuKS1aPB6ONG2K7Xw+buTksC2HEeq1Y9h3fx/8\nXfzhZu4m/8FatgTMzYEbN+Q/1gfIuzIbk8xoPwP/9/T/kJhbu29fRNKaC7PkdUQ1IgILdn+N+HaN\n8Nfos9DU0JTPOPUYTU3grxstMamjPnb9NAUj146DWKLcZTbtdXWxz9MTI58+RYZQyLacOlNvHYNY\nIsbmsM2Y6ztXcYOytAmtLMFssmBpYIkJbSZg3a11tbr/ek4OxET43NycYWUAYmKw/afP8bevBc5P\nvA59bX3mx+AAII2v2fJ3CywcRDizYil6LR6JElEJ27KqpLelJYY3aICxz55BouSznGqRJTxa2RoY\nSIlx6vEp8v3Dt852akRKCpGZGVFhocKGzMkhsrGRJntVFVLzU8l8tTml5te8dkLf6GjaxeczL+r1\n6/9v77zjmr6+//9KInvJRgENCiioIMpwIeDAhai4B1brHlWxy9aPdfxqlY91a22lddY9ahUVFyAK\niCwXGwUFREBk7yTn90e+6QcpSICQMN7Px+M+NO/ce895X5Kc9x3nHLrspE+dt3SkVx+kG6W1vfPr\ndwmkqPiWbFdNpoLyAlmr80kq+XwaEBlJP795I2tVagVMSIxPszN0J9YOlGD4C3Ho1Amwt5dqiIyW\n5swmDgaqBphtNRu7Qnc1qF1yWRlCCwsxR19fsgoVFSFk9lAsdinC1QV3YaJpItn+GT7Jkp/McfKn\nCrz47RDsVi5AdknLcRatiRybjTOWlvB+8wZhhYWyVqfxiGM9WlpBE2cMIW9CyGSPCfH4vCb10yhO\nniQaO1YqoqSdmU2SvM5/TZrbNel9iXjBysr4fPJ4/pzWvXwpWUUqKyl+whDS36BENxKvS7ZvhgZx\n+3gGKcvnUOeZsyj1Q4qs1fkkl7OziRsaSh8qK2WtykeAmTHUza5Hu7BmwBrZbBxOmgSEhABZWc0u\nqqU6s4lDF40umGw5GXvD9tZbN6WsDIOjosBmsbC+a1fJKUGEd0tmY7RlJH5y34sxZmMl1zdDgxk5\ntzMCLhOKLu+GzedbEZP1QtYq1ckkXV2M19bGwoSEFn+qqlbEsR4traAJM4ZXH16Rtrc2FZZLJwxz\nrcydS7R7d7OKkFVmNkmSlJtE2t7alF+WX2cd3/fvSe/hQ9qdlibxhD+F67yon5cKbbq9XqL9MjSN\nmJA80lJ6S2quX1JI6gNZq1Mn5Xw+9QsPpwMtaMoOZsZQO3vD9mJBvwVQU5BCGOa6aOaIq9QKnNnE\nwVTLFKNNR+OX8F/+9R6fCP9JScHSxERc7t0ba4yMJOpPULV/L6Z9+A39Bk7CDyNaUGApBlgO7Iio\nCHWoh3yBEZ6BuBl7TdYq1YoCm41zvXphU2oqoouKZK1OwxDHerS0gkbOGPLK8khzuyalFaQ1qr3E\n4PGIDA2JYmKapXtZZ2aTJDHZMaS3Q4+KK4r/uZZVUUHDnzyhYdHRlNUM6ToF58/T/JnKNNbHpVWm\noGwvvHtdTmaaiaTU/yD9GXZE1urUyel378js0SMqbAFfSDAzhn9zOPIwxpqNhZG6FOLzfwoOB5g9\nu1lmDa3JmU0cLHUtMaTLEPhE+QAAQgoK0D8yEg5qarhtbQ09eXnJCgwKwqZj8/DMgYtzc6+iA7sN\nDGIbRb+LAsKTTGCZ4YRF85Sw9+7PslapVmbq68OpY0csTUxsPfsN4liPllbQiBlDJa+SDHcaUuTb\nyAa3bRaePycyMiKScGLxgweJRo4kkvByu0yJfBtJnXd2ph2pyaT38GHzpVV8/px8nNSo2/ZO9K7o\nXfPIYJA4pcV8Gt4tmpRNbtD3F9dJfK9JEpTweNTr8WP64+1bmeoBZsbwMedjzsNM2wz9OvWTtSpC\nevcGdHSAwECJddmSMrNJEjNdKwhUTLEv4g886tcPbtrakheSloYbi13wnxFs3FwYCH1VCftCMDQb\nSips3Iyzxlh1fez9YhwWHVna4kJoKHM4OG9piW9fvUJMSYms1amXdmEYiAi7Hu2SbvgLcZDwJnRr\ndGarj5iSEthFRcG+9zKw08/ASL4Zlnby8hA+yxmfjSrDX5/dhLm2ueRlMDQrcvIsnIvqB09zJZz7\ndjk89niikt+yciRYqqjgv926YVpMDEr5Lctw/QtxphUtraCBS0kBKQHUY38P4gsku2zTZCQYIqM1\nO7PVxZ/v3pHOw4d0LFMYGsPlmAsdiz4mWSFlZZQ8yo4MflCmK3F/SbZvBqkjEBBt8IgkFbUkGrJp\nIhVVtKzz2gKBgObExtKC+HiZyIeYS0ky/5FvTGmoYXA77Ua/hv/aoDZSY/RootOnm9zNnDlEP/wg\nAX1aAOV8Pi1LSCDTR4/oaTVHjLsv71KP/T0k57HO41H2NDcy+06VDoYdkEyfDC2CvYufkrJSGvX5\narzY3vPSorCqiswfPaI/30l/H0tcw9Dml5IS3icgLD0Mc61baIYtCURcbcmZ2RrK6/JyOEZHI7Oy\nEhH9+8OqmiPGMJNh0FTSxKW4S00XRITSNSvgbhiEyU7LsNx+RdP7ZGgxrPrNCofXFuLlPh/YfjW/\nycmfJIlahw4416sX1iQnI7G0VNbq1I441qOlFTRgxrDk2hLa4L9B7PpSp6REuJyU2fBIokTCqbOT\nE9Hhw5JVSxbczM0l/eBg2vHmTZ0nS3wTfMnqkFWTT57wftpKExar05yz01vkKRYGyeC7J5FU5XJI\nddIC2nHfu0X5pfySnk59w8OpTMInEz8FmBkDkFOSg3Mx57DCrgU/DSorAxMmAGfONLgpEfDnny0/\nM1t98ImwMSUFC+Ljcd7SEl8ZG9fpxTzWbCzYLDZ8E30bLY+OH8cXT7eh2NYKf0w5wWRga8OMW22G\n+1d46OL/LbbN7o9+P4zF86znslYLALC0c2d0V1LCVy9fylqVfyOO9WhpBWLOGLYEbqEFfy8Q15jK\njnv3iGxsxK5eXCycIfTtS2RmRvTwYTPq1szkVFaS65MnNDQqijLF9GK+EHOB7H3sG/ek7+dH20ar\nktXuHp+MwcTQtqisEJD37GhSlXtPKiO+o/W+66i8qlzWalFeVRWZhIbSpexsqchDe998LqsqI/0d\n+vQi60VDxk028PlCZ7fnzz9ZLTGRyMuLSFubaPx4olu3JO4fJ1UeFRRQl5AQ+iY5maoa8CPPF/DJ\n4oAF3U6+3TCBERF0YrAaddmuT+kFbej4FoPYJEfmk6PhM9LQiibuyjEU8iZE1ipRWEEB6T58SK9K\nS5tdlriGQepLSX5+fqN79uwZb2ZmluTt7f1tzffj4+N7Dhw4MFRRUbF8586djXY8OP38NGw62aCX\nXq+mKSwN2Ow6Q2Tw+cC1a8K0nIMHA/Lyws3mq1cBV1dh09YGEeFARgbGP3+OfWZm8O7eHR0asJzD\nZrHx3ZDvsPXBVvGFvnyJu0td8dUYNm7MvwdD9VYYi5yhyXTvp4H7aX2wb4kC8g4fw4ipYVhxagWK\nK4tlppO9ujrWdemCGbGxqBQIZKbHR4hjPSRVeDwep3v37skpKSncyspKOWtr6yexsbEW1etkZ2fr\nhoeH265fv/7Hn3/++cva+kE9MwaBQEC9DvaiOy/vNNqySp0XL4SB9XjCo5g5OUTbtxNxuUT29kTH\njxOVlclYRwlQxOPRjJgYsg4Pp+QmPCFV8avIZI8JBaUG1V85K4ue2BqTzmZVCkwJbLRMhrZF9psy\nmtYnnFRVUkjfcyrdTvKTmS4CgYDcnj2jr5KTm1UOWuKM4fHjx/ampqbJXC43VU5OrmrGjBln//77\n7wnV6+jq6ubY2tpGyMnJVTVWzq2Xt8BhczDcZHjTlZYWvXoBenoI/y0S8+YBZmZAXBxw/jwQFgbM\nnQsoKspayaYRV1IC+8hIKLHZCLWxQXclpUb31YHdQbxZQ3Ex3kwZiXHj8nHA43c4cZ0aLZOhbaFr\nrIhzz2xxaRfAurQTEyd8wMz985BXlid1XVgsFo717Ilz2dm4npsrdfk1kWroyIyMDENjY+M00Wsj\nI6P0sLAwh8b0tWnTpn/+7+zsDGdn539e7wrdhbUD1raa0ybl5cC5c8DB3BvI+ZaDZRuAn38WhlJq\nK5zLzsbKpCRs79YNCzp1kkifc63nYkvQFkS8jYBtZ9t/V6iqQt7MSRjj+AZrXTdieu/pEpHL0LZw\nXcxF8kwB1k/qjsNfe8Pv3nf4fbMLJltL9/OiLSeH05aWmBITg4j+/WGkoNDkPgMDAxHYiHhsUjUM\nLBZLYjFnqxuG6jzLeoYX2S8wo/cMSYlqNlJTgUOHgKNHgf79gR+2KmDMSlNwVrwBVFRkrZ5EqBQI\n8NXLl7iem4vbVlawUZNcgiSFDgr4etDX2PpgK/6a/tfHbxKhfMkCTDSPguvguVg7qIXFyWJoUaio\nsbHnrj0+88vCzFlemDs+Az4LZuPYlzthoGogNT2GaGhglaEhZsXGwr9v3wbtvdVGzYfmzZs3i9VO\nqktJhoaGGWlpacai12lpacZGRkbpkpSxK3QXVtqvhEKHplvb5kAgAG7dAtzdAVtbYf6E4GDg5k3A\nbY4mOIMcgCtXZK2mREivqIDTkydILS9HRP/+EjUKIhb2W4jQtNB/nU0XbPgPPpO7Dj1bJ+wcs1vi\nchnaJjaj9fEiyxwbXTQR9NM+mLofxO9Bv4r2NqXCui5doMhmY3NqqtRk1kSqhsHW1jYiKSnJLDU1\nlVtZWSl/7ty56e7u7ldrq0tEDTaVmUWZ+Dvhbyy1Xdp0ZSVMXh6wezfQowewbp3QMLx5A+zaJdxP\n+IdmTvspLe58+AC7yEhM0NHBld69oSkn1yxylOWU4TXAC9sebvvfxUOH8HXyL3jb3wwnp54Gm9UK\nj24xyIwOcix8c9wGMY/lYP3SA194DMaA1Z5I+fBKKvLZLBZOWljgj8xM3M2T/n4HAOn7Mdy4cWOM\nubl5Qvfu3ZN/+umn74gIv/7665Jff/11CREhMzPTwMjIKE1dXb2gY8eOecbGxm+KiopUq/eBOk4l\nfX/ve1p+fXnTt+4lSHQ00cKFwqgXs2YRBQfXk0RHFCJDxgk9GgtfIKAtKSnUKTiY/D98kIrMgvIC\n0vmvDiW8TyD66y/a7apOFrtNKbc0VyryGdouAgHRiQ0xpKqQRYp2+2n75Z8kF8SxHu58+ECdg4Pp\nnQTT10LMU0kskuIUSVKwWCyqqXdJZQm4e7kIXRAKUy1TGWkmpLISuHQJOHBAOCtYsgRYtAjQFzf3\ny+efCxP5rF3brHpKmtyqKnjGxaGQz8d5S0t0lsDmmbhsDtyM13GhGHMiFF4TFRG85DG6duwqNfkM\nbZvctxVYPC4a15M7gTtxCy7vWANLgz7NLndDSgoeFRbilpUV2BI4TMNiscRbjRHHerS0glpmDAcf\nH6SJZyc21pBKhLQ0ov/8h8jAgGjYMKJLl4galf/b35/I2lri+jUn4YWFxA0NpbVJSVQpTXfsqiqi\nCxcod6gdaa1jk86PGhSdGS09+Qztitt/pJCuairJW5yjrw+vowqe5J7ma6NKICDHqCjampoqkf7Q\nnkJi8Pg8Mt1nKp6zk4QRCIShjjw8iDQ1iVauJIqNbWKnfD6RsTHRs2cS0bE5EQgEdCgjg3QePqSL\nUor3QkRE+flEO3cKPQAHDSK6cIGORx6hgJQA6enA0C4pLebTctdgklfMIsPxXhT28kGzyksrLyf9\n4GAKystrcl/tyjBcibtCdoftpBo+uaCAaP9+IgsLIktLooMHiQoLJShg3Tqir7+WYIeSp5jHozmx\nsdT78WNKkEAWOrF4+ZJo9WqhFZ45kygsTDpyGRhqEH37HXXTeUFyxoH0+dY1VFLZfN8B3/fvyTgk\nhHIqK5vUT7syDI5HHOnM8zNNGjBxiYkhWr5c+Ls0ZQpRQEA9m8lNEVQtREZLI76khHo/fkyesbFU\n3Nw6CgRE9+8TTZwojCD47bfCdTsGBhnD4xH9OC+M5BVySMtpC92KvNpssr5KTqZxz5416QFYXMPQ\n6s/xhWeE43XBa0yxnNJsMqqqgIsXARcXYPhwQFsbePYMuHABcHYGmsXB2tISMDAAAgKaofOmcTEn\nB0Oio7HS0BDHe/aECofTPIIqK4UJJ2xthbv3I0cCr18D27cDRkbNI5OBoQFwOMD6o/ZIjFBAtzej\nMM7VBBPXfIGCsnyJy9pqYoL3VVXYnS5R16/aEcd6tLSCajOGGRdn0M6QnY22oJ8iM5No82bhg/uQ\nIURnzhBJ8ORY/ezZQ+TpKUWBn6aSzyevpCTihoZSuETXzWqQk0P0449EnTsTDR9O5OvbuuOLM7QL\nBAKiIz88IWWlTFLp/wud8TsucRkpZWWk+/AhhRUUNKo92sNS0uv816TlrSXRhCsCAdGDB0QzZgjd\nCRYvJnryRGLdN4ysLCINDWFmHhmTXl5Og6OiaMzTp5TbxHXOOomNFQ54x45E8+cTPX3aPHIYGJqR\n3MwKGtvvPnVQfUNDZq+hrALJ+iRdys4mk9BQymvEkUdxDUOrXkraF7YP8/rOg4aiRpP7KikBDh8G\n+vYVuhE4OAApKcBvvwHW1hJQtjHo6QmTMPz1V/11m5GAvDzYRUZitJYWfPv0gZYkvZiJgNu3gTFj\nhGt1nToB8fHAkSOAlZXk5DAwSAktA3lcjxyKa/srEHPtC3SxD8H+4/tED7VNxkNXF2O1tbEoIUFi\nff4LcaxHSysAqKC8gLS8tSg1L7XBVrM6CQnCQy5aWkTu7i0wK9rZs0SurjIRzRcI6KfUVDIIDqY7\nkvZiLi0l8vEh6tWLqE8foiNH2kbCCQaGapSV8Onz0QHEUcymXmO/p5S3CZLpl8+nvuHh9Et6wzIR\noq17Pu8M2YnHGY9xdsrZBrfn84Hr14GDB4HoaGDBAqF3MpcreV2bTFkZYGgIvHgBdO4sNbF5VVWY\nGx+P3KoqnO/VSyIhgAEAmZnAL78Ip2d2doCXFzBsWDPt4DMwtAyi776D+5wsvJMrxHcrH2DTN+ua\nHMMrsbQUg6OjccfaGn1VVcVq0+Y9n7vs7kJh6Q07w56dTbRtG1HXrq0sK9rnnxPt2CE1cZGFhWQS\nGkqrk5KoQlLTp+hoorlzhed8ly8XTtUYGNoRPB7R+vn3qYNiDnUZ4k3PYprug3Pq3Tsyf/SICsXc\nb0Bb32PootEF9ob2YtV9/FiYAc3MDEhIEB49bVVZ0aQUcZWI8HtmJkY9e4bt3bphj6kp5JuSVJrP\nB/7+W3imd/x44RHc5GThVM3cXGJ6MzC0Bjgc4McjQ5EUIQeNd4NgM1QVS702oopX2eg+Z+nrw7Fj\nRyxLSpLsfoM41qOlFQB0O/n2Jy1jaSnR0aNEtrbCqAne3sJTkK0SPp+oS5dmPaVTwuPRvLg4sgwL\no7imejEXFRHt20fUvTuRnR3R6dNEzXWSiYGhFSIQEB3cFEYKyhmkbe1D9wMbn2+6hMcjy7AwOiJG\nRGa09T2GuvROSflfVjRbW2DFCuGBl+bywZIa69cLHb527JB418llZZj84gV6qajgcI8eUG3sYL1+\nDezfLxz8YcOANWuAQYOY/QMGhjrIy66Ex7j7CIq3wIQJPjjl8xWUlBqe0CqmpATOT57gft++sPxE\n9kdx9xha7VJSdQQCwM8PcHMT7mfy+UBo6P9lRXNrA0YBEC4nnT4tvDkJcuX9ewyKisLizp1xysKi\ncUYhNBSYNg3o1094/DQyUugWPngwYxQYGD6Bpp48AsJH4tK+fNy9Pgd6Vv64fPZMg/vppaIC727d\nMC02FqUS+I1o1TOGvDzhw+mhQ4CqqnB2MGsWoKwsaw2bCTs7YOtWwNW1yV3xiPD9q1c4l52N8716\nwUFdvYEd8IRJJ3bvBnJygNWrgfnzgWZI38nA0B6oKCfM9fDDxUBbDHHywd9/fo6O2uLnmyYizImL\ngzKHA58ePWqtI+6ModUahgULCBcvAuPGCQ3CwIHt4OF03z4gPLzJG9GZFRWYERsLRTYbpywtodMQ\nh7W8PMDHR5iFyMREeNx0/Pg2Mi1jYJA9ofdSMNHzA/JZldi79hmWfrlE7LZFPB76R0ZiM5eLOT1n\n1gAAGYBJREFUmbVkBmvzS0kmJsITRqdOtaNl7BkzgGvXgOLiRndxPz8ftpGRcNHUxA0rK/GNQlIS\nsHIl0L078Pw5cOUKcP8+MHEiYxQYGCTIwOEmyEzvj6WjC7BigwesBu5DelKiWG3VOnTAOUtLrEpO\nRlJpaaN1aLWGYf36BqTKbCvo6QGOjo0KkUFE2PHmDabHxuJIz57YxOWCU581JQL8/QF3d+F+gYaG\n0NHu5EnhfgIDA0OzwGYDe/8YjfhwoOxDb3AHCLBp7W6QQFBvWxs1NWzicjE9NhYVYtSvjVa7lNQa\n9ZYI588Ll3Lu3BG7ST6Ph/nx8XhbUYELvXqhS33OGxUVwJkzwJ49wpNQa9YAc+a04c0bBoaWjfem\ne/jPzh7o3DUAN34zR6/BDp+sT0SYEhMDQwUF7DMz++d6m99jaI16SwRRiIznz4X/1sPT4mJMjonB\nKE1N7DI1hcKnHNays4FffxXu5ltZCfcPXF2Fjy8MDAwyJftdMcZN9EdUjC0Wup3BoeOrwJaveyk4\nn8eDTUQEdnXvjkm6ugDawR5Du0VJCfDwEB5drYdj795hxNOn2MLl4qC5ed1G4cULYOFCoEcPID0d\nuHsXuHULGD2aMQoMDC0EPQNVhD9yx9E9r3Hizljo9biDoAu36qzfsUMHnLW0xJLERKSWlzdIFvOt\nb43MnfvJk0nlAgEWJSRg+5s3COzbF7Nq24wRCIAbN4RZ0VxdhREEExOFwe169Wo+3RkYGJrE3AUD\nkfvGDLaWJXD+rD8mjtyLivyCWus6qKvj2y5dMCM2FlUN2G9glpJaIwIB0K2bMA5RjWQRr8rKMCUm\nBmZKSvi9Rw+odejwcduSEqFR2bNHOPvw8gKmTwckFT2VgYFBaty+9RzTFpaAV8nG8W9TMHnt9H/V\nERDB/cULWCorY4epKbOU1GZhs4WbwSdOfHT52vv3GBAVhc8MDHDW0vJjo5CRAXz3nXBm4OcnzEAU\nFSWcfTBGgYGhVeI6qg9yUx0w2S0VU/8zDENsfZD/6uOc0GwWC8d69sSZ7Gyx+2UMQ2tFFCKDx/vH\ni3l5UhKu9O6N1UZGYImOokZEALNnA336CGcLoaFCHwQnp3bi/MHA0LbhcFg4/sc0RD4qRkqpEfT6\nlWG/1xHhcfP/Q0dODqcsLMTuk1lKas04OCBvwwZMNjICm8XCaQsL6MnLC+MpXbkiDFeRlgasWiXM\nRtSxo6w1ZmBgaEaICOs2XsbPe+3Q0yAUN471QteBvf95nzmV1B7w9MTF7dsxWEMDt6ysoFdeLjQG\npqbAzp3C+EUvXwJfftkujEJgYKCsVWgxMGPxP9rTWLBYLHhvmYyXMYoQaAHdR2rj++m/gSqrGtSP\n1A2Dn5/f6J49e8abmZkleXt7f1tbnVWrVu0zMzNLsra2fhodHW0jbR1bDTNmICMiAv+vqAictWuF\n+wdhYcDZs0BICDB1KlBz87kN055+AOqDGYv/0R7Hgmukh7jQ6dixMwo/BwxGl26BeHrxodjtpWoY\n+Hw+Z+XKlQf8/PxGx8bGWp45c2ZmXFzcRwtfN27cGJucnGyalJRkdvjw4cXLli07JE0dWxU6OkJj\n4OQEyMsDT54IjYLDp70iGRgY2gdeS8YhM7kLjKzT0W9uT7HbSdUwPH782N7U1DSZy+WmysnJVc2Y\nMePs33//PaF6natXr7p/9tlnxwHAwcEhLD8/v2NWVlZ7i4okPpMmCZ3SvL2BLl1krQ0DA0MLQ1td\nHaHX5+PPcy/EbiPVdYaMjAxDY2PjNNFrIyOj9LCwMIf66qSnpxvp6+tnVa/HYk7U/MPm7dtlrUKL\nYfPmzbJWocXAjMX/YMaiYUjVMLBYLLGOEtXcNa/ZTpxddQYGBgaGxiHVpSRDQ8OMtLQ0Y9HrtLQ0\nYyMjo/RP1UlPTzcyNDTMkKaeDAwMDO0ZqRoGW1vbiKSkJLPU1FRuZWWl/Llz56a7u7tfrV7H3d39\n6okTJ+YCwKNHjwZ07Ngxv+YyEgMDAwND8yHVpaQOHTrwDhw4sHLUqFG3+Hw+Z8GCBX9YWFjE/fbb\nb0sAYMmSJb+NHTv2xo0bN8aampomq6iolBw9enS+NHVkYGBgaO+0Os9nPz+/0WvWrNnD5/M5Cxcu\n/P3bb7/1lrVOsuDzzz8/cv369XF6enrZz58/7yNrfWRJWlqa8dy5c09kZ2frsVgsWrx48eFVq1bt\nk7VesqC8vFzRycnpfkVFhUJlZaX8hAkT/t62bdt3stZLlvD5fI6trW2EkZFR+rVr18bLWh9ZweVy\nU9XV1Qs5HA5fTk6u6vHjx/Z1ViaiVlN4PB6ne/fuySkpKdzKyko5a2vrJ7GxsRay1ksWJSgoyDEq\nKsqmd+/ez2Wti6xLZmamQXR0dF8iQlFRkaq5uXlCe/1cEBFKSkqUiQhVVVUdHBwcHj148GCIrHWS\nZdm5c+faWbNmnRo/fvxVWesiy8LlclNyc3O1xKnbqkJiiOMH0V5wdHR8oKmpmSdrPVoCBgYG7/r2\n7fsEAFRVVYstLCzi3r5921nWeskKZWXlUgCorKyU5/P5HC0trQ+y1klWpKenG924cWPswoULfyfm\nNCPEHYNWZRhq83HIyMioP78lQ7shNTWVGx0dbePg4BAma11khUAgYPft2/eJvr5+louLS4ClpWWs\nrHWSFV5eXrt37NjxNZvNFj9LTRuFxWLRiBEj7tra2kb4+Pgs+lTdVmUYxPWDYGifFBcXq06ZMuXi\n3r17V6uqqhbLWh9ZwWazBU+ePOmbnp5uFBQUNDQwMNBZ1jrJAl9fXzc9Pb1sGxubaGa2AAQHBw+O\njo62uXnz5piDBw+uePDggWNddVuVYRDHD4KhfVJVVSU3efLkS3PmzPlz4sSJV2StT0tAQ0OjYNy4\ncdcjIiJsZa2LLAgJCRl09epVdxMTk5SZM2ee8ff3HzZ37twT9bdsm3Tq1CkTAHR1dXMmTZr0V5vZ\nfK6qqurQrVu3lykpKdyKigr59rz5TERISUnhMpvPBIFAwPL09DyxZs2a3bLWRdYlJydHJy8vryMR\nobS0VMnR0THo7t27w2Wtl6xLYGCgk5ub2zVZ6yGrUlJSolxYWKhGRCguLlYZNGhQ8K1bt1zrqt+q\nZgzV/SAsLS1jp0+ffs7CwiJO1nrJgpkzZ54ZNGhQSGJiormxsXFae/b3CA4OHvznn3/OCQgIcLGx\nsYm2sbGJ9vPzGy1rvWRBZmZmp2HDhvn37dv3iYODQ9j48eOvDR8+/J6s9WoJtOel6KysLH1HR8cH\nos+Fm5ubr6ur6+266rc6PwYGBgYGhualVc0YGBgYGBiaH8YwMDAwMDB8BGMYGBgYGBg+gjEMDAwM\nDAwfwRiGNsCxY8fmsdlsgaioqqoWm5iYpHh4eFy+cOHC1Jr1U1NTuWw2WyAKby4OgYGBzps3b95I\nbcRR6MKFC1M7d+78try8XFES/Yn+Bm/evJFYftXm6LO1IfqsHj9+/DNx21y9etXdwMDgXVFRkVpz\n6tamkfX5WqY0vRw9enQei8USXLp0ySMsLMw+KCjI8eTJk3NmzJhxhsPh8EaMGHGnrKxMUVS/oqJC\nPiwszP79+/fa4srYuHHjJhaLJeDz+WxZ329TS0VFhbyJicmrAwcOrJBUnzk5OTphYWH2FRUV8i25\nz9ZWUlJSuCwWS3D8+PG5DWlnb28ftm7dum2y1r+1FpkrwJSmF5FhePnyZbea7126dMmDzWbzv/ji\ni31NkSEyDDwejyPr+21qOXny5BwVFZXi4uJiFVnrwhRCeXm5Ql3vNdYwHDlyZL66unoB8zduXGGW\nkto4Hh4elydMmPC3j4/PorKyMiWg9ul5eHi43ciRI+/o6Oi8V1ZWLu3evfvLFStWHASATZs2bdqy\nZcsPACAnJ1clWrIStd24cePmfv36RWloaBTo6urmDB8+/F5YWJhDdT0CAwOd2Wy24Nq1a+NXrlx5\nQFdXN0dXVzfH09PzZEFBgUb1ujwer4O3t/e3lpaWsUpKSmV6enrZY8aMuZmQkNBDVCcnJ0d36dKl\nvxoZGaUrKiqWW1hYxNUXGEyEj4/PInd396sqKiol1a+z2WzBhg0b/t+OHTu+7tKlyxtVVdViNzc3\n35ycHN3MzMxOkydPvqShoVHQtWvX1//973+/qd62tmWf06dPz7KxsYlWU1Mr0tDQKLCysnp2+PDh\nxeKMeV19crncVE9Pz5Nnz56dYWFhEaeqqlpsZ2cXHhwcPLjmfe7Zs2cNl8tNVVJSKnNwcAgLCQkZ\nxOVyU+fPn3+0rrHh8/mcjh075m/dunW96Nrz58/7sNlsgaOj44PqdY2MjNK/+eab/4peZ2Zmdpo7\nd+4JXV3dHEVFxXJra+unp06dml3bOD148MBx6tSpFzQ1NfMGDBjwCABKS0uVly9f/ou2tnaumppa\n0YQJE/5OT083qqljfeMGAFOmTLlYXl6ueObMmZl13StD3Ug1gxuDbBgzZszNK1euTIyMjOw/ZMiQ\nh6LrIk/Q4uJi1VGjRt0aMGDAo+PHj3+mpqZWlJKSYhIaGjoQABYtWuSTkZFh+McffywIDg4ezOFw\n+NX7z8jIMFyzZs2erl27vi4pKVE5efKk59ChQ4MiIyP79+7d+0X1uqtXr947fvz4a2fOnJkZHx/f\n85tvvvkvh8PhHzt2bJ6ojiicupeX1+4RI0bcLSsrU3rw4IFjZmZmpx49eiQUFhaqDxky5GFFRYXC\n5s2bN5qYmKT4+fmNXrZs2aGKigqFlStXHqhrLIqKitRCQ0MH7tmzZ01t7584cWKulZXVs99++23J\nu3fvDNasWbNnzpw5f+bl5WlOnDjxyooVKw6eP39+2rp167b36dPn+ZgxY27W1s/Dhw+HeHp6nly9\nevXenTt3fikQCNhxcXEWIiNY35jXBYvFogcPHjgmJiaab926db2CgkLFhg0b/p+bm5tvamoqV0ND\nowAAfv/994Vr167dtXDhwt+nTp16ITk52XT27NmnCgoKND7lAczhcPhOTk73/f39h61fv34rAPj7\n+w9TUlIqCw8PtystLVVWVlYuTUhI6PH27dvOIq/qkpISFScnp/sFBQUa27Zt+87Y2Djt5MmTnp6e\nnidLS0uVFy1a5FNdzuzZs0/NmjXr9LJlyw7xeLwOgDCD4/nz56dt2rRpk52dXfjt27ddZ82adbp6\nO3HHTU1Nrcja2vrprVu3Ri1cuPD3T40pQy3IesrClKaXTy0lERH8/PxGsVgswfnz56cS/Xt6Hh4e\nbstisQTPnz/vXZcMcfcYeDwep6qqqkOPHj3iV69evUd0PSAgwJnFYgnmzZt3tHr9lStX7ldUVCwT\nvb53794wFosl2L9//8q6ZGzZsmWDoqJiWXJycvfq1xctWnRYR0cn51M63r9/fyiLxRLcv39/aM33\nWCyWoEePHvHV269du3Yni8USbN269fvq96inp5c1f/78IzX/Bq9fv+5CRNixY8dXWlpauXXpIc6Y\n1+yTiNC1a9dULS2t3Pz8fA3RtYiIiP4sFktw+vTpmUQEPp/PNjIyShs3bpxv9f4uX748icViCarr\nXVvZtWuXl5KSUmllZaUcEWHChAlXli1b9ouKikqxKL7OoUOHlsrJyVWKkgLt379/ZW3jOmLEiDt6\nenpZAoGAVf2e1q5du7N6vfj4+B4cDofn7e39TfXry5Yt+6Whn1VR+fzzz//o2rVrqjS+g22tMEtJ\n7QD6v5NEdT0pmpmZJXXs2DF/8eLFh0+dOjW7egRbcbh79+4IFxeXAB0dnfdycnJV8vLylYmJieaJ\niYnmNeuOGzfuevXXvXv3flFRUaGQnZ2tBwC3b992ZbFYVPMJszp+fn6jBwwY8IjL5abyeLwOouLq\n6no7NzdXOzY21rKutllZWfoAoK2tnVvb+yNHjrxTfZmsR48eCQAwatSoW6JrHA6Hb2pqmlzbMocI\ne3v7x3l5eZqenp4nfX193fLz8ztWf9/c3DyxsWM+cODAUNHMABCOISCMNgwIk9NkZGQYTp069UL1\ndu7u7lc7dOjAq6//YcOG+ZeXlyuGhIQMEggE7KCgoKGjRo26NWTIkIf+/v7DAOEsws7OLlyUFCgo\nKGiokZFR+tChQ4Oq9zV79uxTOTk5ujX/JpMmTfqr+uuwsDAHgUDAnjZt2vnq12fMmHG2+uuGfFZ1\ndHTei/7eDA2DMQztANGXRxR2tyYaGhoFAQEBLp07d367fPnyX7p27fq6T58+zy9fvuxRX99RUVH9\nxo4de0NdXb3wyJEjn4eFhTmEh4fbWVtbP63tKGjNbGIKCgoVgDBXMQDk5uZqa2lpfRBdr43s7Gy9\n+/fvO4mMkKhMmzbtPIvFotzcXO369K6Lmlnx5OXlK2u7LicnV/Wpo65Dhw4NunDhwtS0tDRjDw+P\ny3p6etkjR468I8rPra6uXtiYMWexWFTfGGZmZnYCAD09vezq9TgcDl9HR+d9fWNgZWX1TFtbO9ff\n339YdHS0TWFhobqzs3Ogi4tLQEBAgAsg3DMaNmyYv6jNhw8ftGr7fBkYGLwTvV/9es26Ip319fWz\nql+veQ9N+awyiA9jGNoB169fH6ekpFTWv3//yLrqWFtbP7148eKUvLw8zdDQ0IHdu3d/OW3atPMx\nMTG9PtX3pUuXJsvLy1devnzZw93d/aqdnV14//79I2v+EIiLjo7O+w8fPmh96kdXR0fn/eDBg4Mj\nIiJsa5bw8HC7T92n6IenKcZDXCZPnnwpMDDQOT8/v+Nff/01KTMzs9Po0aP9RDO4xo55fYh+dEWz\nMBF8Pp+Tk5OjW197FotFon0GUcRaDQ2NAhcXl4CoqKh+wcHBg9+/f6/j4uISIGqjpaX1QfTjXp13\n794ZiN6vKaM2nWs+4df2xC/uuL1//15HZJgYGgZjGNo4ly5dmnzt2rXxS5cu/VVRUbG8vvpsNlvg\n4OAQtmXLlh8EAgE7Pj6+J/C/p9LS0lLl6vVLS0uVa6ZN9Pf3H9bQ5SgRo0aNukVErN9//31hXXVG\njx7tFxcXZ2FsbJzWr1+/qJrlU9nbbGxsojkcDv/Zs2dWjdGvMSgrK5eOGzfu+uLFiw9nZmZ2qmk0\n6xrzxmJkZJRuZGSUfv78+WnVr1+5cmUin8/niNPHsGHD/B8/fmzv6+vrJpoZ9O/fP1JFRaVk06ZN\nmxQUFCoGDx4cLKrv7OwcmJ6ebhQSEjKoej+nT5+epa+vn1VfetEBAwY8YrPZgnPnzk2vfv3s2bMz\n6mpT37g9e/bMytbWNkKc+2X4GOZUUhsiOjraJjs7W6+yslL+zZs3XXx9fd0uXrw4xdXV9fa2bdu+\nq6udr6+v2+HDhxdPmjTpLy6Xm1pSUqKyb9++Verq6oUDBw4MBYBevXrFAMDOnTu/HD16tB+Hw+Hb\n2tpGjBkz5ubevXtXz5s379i8efOOJSYmmv/444//MTQ0zKBGeEk7OzsHTp48+dLatWt3paWlGbu4\nuARUVVXJBQUFDXVzc/N1cnK67+XltfvcuXPTHR0dH3h5ee02NzdPLCkpUYmPj+/58OHDIVeuXJlY\nV/9qampFAwYMeBQUFDT0U6eXxOFT9/fDDz9syc7O1nNxcQno1KlTZnp6utG+fftW2djYRGtra+eK\nM+YNlSmCzWYLNm7cuHnRokU+ixYt8pkyZcrFV69edfP29v5WQ0OjQJz8x9XHfd26ddsB4VLU0KFD\ng3x9fd2cnJzuV1/umzdv3rG9e/eu9vDwuLx169b1hoaGGadOnZp99+7dEYcPH15cXy4Ec3PzxFmz\nZp3+4YcftggEAratrW3E7du3XW/evDmmej1xx62oqEjt2bNnVosXLz5c370y1IKsd7+Z0vRy7Nix\nz1gslkBUlJSUSrt27Zrq4eFx6eLFi5Nr1q95KikhIcF8+vTpZ01MTF4pKiqW6erqZo8bN8738ePH\ndqI2fD6fvWLFigN6enpZbDabz2az+aL39u/fv9LExOSVkpJSqb29fdi9e/eGOTs7B7i4uPiL6gQE\nBDiz2Wz+vXv3hlXX5ejRo/PYbDa/+skbHo/H2bp16/fm5uYJ8vLyFSJ9EhMTzUR18vLyOnp5ee0y\nMTF5JS8vX6Gnp5c1dOjQ+3v37l1V33gdP358rrKycokoo5WosFgswYYNG7bUpl/NE1/Ozs4Bjo6O\nQXXdx/Xr18eOGjXKr1OnTm8VFBTKjY2N3yxcuNAnMzPTQNwxr21suFxuiqen54ma98RisQSbN2/+\nofq1PXv2rO7atWuqoqJimZ2d3eMHDx4M0dTU/FDzRFBdxcDAIFNeXr5CdPKIiLB79+41bDabX1MW\nESEzM9PA09PzhI6OTo6CgkK5tbX1k1OnTs0SZzyJhBnnli1b9ouWllauqqpq0YQJE64EBwcPauhn\nlUjo4KamplZYVFSkKuvvZ2ssMleAKUyRdqmoqJDncrkp+/bt+0LWukiziI56/vnnn7NlrUtzFwcH\nh0fffPONt6z1aK2FyeDG0C65cOHC1DVr1ux5+fJld3H2Xlobqamp3AMHDqx0dHR8oK6uXhgXF2fx\n008/fa+oqFj+4sWL3m3xnkVcu3Zt/KJFi3ySkpLM1NTUimStT2uEMQwMDG2QrKws/Xnz5h2Liorq\nl5eXp6mpqZk3cuTIO9u3b19nZGSULmv9GFo2jGFgYGBgYPgI5rgqAwMDA8NHMIaBgYGBgeEjGMPA\nwMDAwPARjGFgYGBgYPgIxjAwMDAwMHwEYxgYGBgYGD7i/wODa0FKnn2T3QAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x4e1dcd0>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The probability of finding a word set of length 5 with the same words as another is 1.5%.  As a result, if two word sets are equal, we can only be about 98% confident that the two word sets correspond to the same text.\n",
      "\n",
      "For cases where the word sets share 0 or 1 words, we only have a confidence of about 75%."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Naive Bayes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(Copied from scikit-learn)\n",
      "\n",
      "Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes' theorem with the \"naive\" assumption of independence between every pair of features. Given a class variable $y$ and a dependent feature vector $x_1$ through $x_n$,\n",
      "Bayes' theorem states the following relationship:\n",
      "\n",
      "$$\n",
      "P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots x_n \\mid y)}\n",
      "                                    {P(x_1, \\dots, x_n)}\n",
      "$$\n",
      "\n",
      "Using the naive independence assumption that\n",
      "\n",
      "$$\n",
      "P(x_i | y, x_1, \\dots, x_{i-1}, x_{i+1}, \\dots, x_n) = P(x_i | y)\n",
      "$$\n",
      "\n",
      "for all $i$, this relationship is simplified to\n",
      "\n",
      "$$\n",
      "P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) \\prod_{i=1}^{n} P(x_i \\mid y)}\n",
      "                                    {P(x_1, \\dots, x_n)}\n",
      "$$\n",
      "\n",
      "Since $P(x_1, \\dots, x_n)$ is constant given the input, we can use the following classification rule:\n",
      "\n",
      "$$\n",
      "P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y) \\\\\n",
      "\\Downarrow \\\\\n",
      "\\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i \\mid y),\n",
      "$$\n",
      "\n",
      "and we can use Maximum A Posteriori (MAP) estimation to estimate: $P(y)$ and $P(x_i \\mid y)$; the former is then the relative frequency of $y$ in the training set.\n",
      "\n",
      "The different naive Bayes classifiers differ mainly by the assumptions they make regarding the distribution of $P(x_i \\mid y)$.\n",
      "\n",
      "Naive Bayes uses an estimator $\\hat{\\theta_{yi}}$ for $P(x_i \\mid y)$ of the form:\n",
      "\n",
      "$$\n",
      "\\hat{\\theta_{yi}} = \\frac{N_{yi} + \\alpha}{N_y + \\alpha * n}\n",
      "$$\n",
      "\n",
      "where $y$ is the class, $i$ is the word (feature), $N_{yi}$ is the number of times feature $i$ occurs in class $y$, and $N_y$ is the total number of times feature $i$ occurs in all classes.  If the word $i$ is in the instance but none of the classes, we let $N_{i}$ equal $N_c$, the number of classes, so that each class has equal probability.\n",
      "\n",
      "To get an understanding of the estimator, we can consider its values at extremes.  Let the parameter $\\alpha$ be set to 1. Since each set can only contain once instance of a word, $N_{yi}$ is either 0 or 1.\n",
      "\n",
      "If $i$ is present only in one of the training classes and is present in this instance, we get\n",
      "\n",
      "$$\n",
      "\\hat{\\theta_{yi}} = \\frac{2}{3}\n",
      "$$\n",
      "\n",
      "If $i$ is present in all of the training classes and is present in this instance, we get\n",
      "\n",
      "$$\n",
      "\\hat{\\theta_{yi}} = \\frac{2}{N_c + 2}.\n",
      "$$\n",
      "\n",
      "If $i$ is present only in one of the training classes and is not present in this instance, we get\n",
      "\n",
      "$$\n",
      "\\hat{\\theta_{yi}} = \\frac{0}{3}\n",
      "$$\n",
      "\n",
      "If $i$ is present in all of the training classes and is present in this instance, we get\n",
      "\n",
      "$$\n",
      "\\hat{\\theta_{yi}} = \\frac{2}{N_c + 2}.\n",
      "$$\n",
      "\n",
      "Bernoulli Naive Bayes considers both $P(i | y)$ and $P( \\neg i | y )$, penalizing the absense of the feature.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "class BernoulliNaiveBayes(object):\n",
      "    \"\"\"\n",
      "    Assumes classes are distributed uniformally so p(c) = 1 / N_c.  As a constant, it can be factored out and ignored.\n",
      "    \"\"\"\n",
      "    def __init__(self, alpha=1.0):\n",
      "        self.alpha = alpha\n",
      "        self.word_classes = defaultdict(list)\n",
      "        self.total_classes = 0.0\n",
      "        \n",
      "    def train(self, labelled_classes):\n",
      "        self.total_classes = float(len(labelled_classes))\n",
      "\n",
      "        for label, word_set in labelled_classes:\n",
      "            for w in word_set:\n",
      "                self.word_classes[w].append((label, word_set))\n",
      "                \n",
      "    def _log_likelihood(self, word):\n",
      "        class_features = float(len(class_word_set))\n",
      "        total_features = float(len(self.word_classes))\n",
      "        log_likelihood = np.log(1.0 + self.alpha) - np.log(class_features + self.alpha * total_features)\n",
      "        \n",
      "        return log_likelihood\n",
      "\n",
      "    def classify(self, instance):\n",
      "        instance_label, instance_word_set = instance\n",
      "        \n",
      "        # base class -- no match\n",
      "        best_match = (0.0, None)\n",
      "        \n",
      "        possible_classes = []\n",
      "        for word in instance_word_set:\n",
      "            possible_classes.extend(self.word_classes[word])\n",
      "        \n",
      "        for label, class_word_set in possible_classes:\n",
      "            log_sum_likelihood = -np.log(self.total_classes)\n",
      "            for word in class_word_set:\n",
      "                n_word_classes = float(len(self.word_classes[word]))\n",
      "                if word in instance_word_set:\n",
      "                    log_sum_likelihood += np.log(self.total_classes) - np.log(n_word_classes)\n",
      "            \n",
      "            likelihood = np.exp(log_sum_likelihood)\n",
      "            best_match = max((likelihood, label), best_match)\n",
      "            \n",
      "        return instance_label, best_match[1], best_match[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bnb = BernoulliNaiveBayes(alpha=1.0)\n",
      "bnb.train(training_word_sets)\n",
      "print bnb.total_classes\n",
      "print len(validation_word_sets)\n",
      "random_word_set_classifications = map(lambda instance: bnb.classify(instance), validation_word_sets)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bnb = BernoulliNaiveBayes(alpha=1.0)\n",
      "bnb.train(training_word_set_0)\n",
      "print bnb.total_classes\n",
      "print len(validation_word_set_0)\n",
      "offset0_word_set_classifications = map(lambda instance: bnb.classify(instance), validation_word_set_0)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bnb = BernoulliNaiveBayes(alpha=1.0)\n",
      "bnb.train(training_word_set_1)\n",
      "print bnb.total_classes\n",
      "print len(validation_word_set_1)\n",
      "offset1_word_set_classifications = map(lambda instance: bnb.classify(instance), validation_word_set_1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bnb = BernoulliNaiveBayes(alpha=1.0)\n",
      "bnb.train(training_word_set_2)\n",
      "print bnb.total_classes\n",
      "print len(validation_word_set_2)\n",
      "offset2_word_set_classifications = map(lambda instance: bnb.classify(instance), validation_word_set_2)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random_probs = map(lambda t: t[2], random_word_set_classifications)\n",
      "offset0_probs = map(lambda t: t[2], offset0_word_set_classifications)\n",
      "offset1_probs = map(lambda t: t[2], offset1_word_set_classifications)\n",
      "offset2_probs = map(lambda t: t[2], offset2_word_set_classifications)\n",
      "\n",
      "random_densities, random_bins = np.histogram(random_probs, bins=20)\n",
      "offset0_densities, offset0_bins = np.histogram(offset0_probs, bins=20)\n",
      "offset1_densities, offset1_bins = np.histogram(offset1_probs, bins=20)\n",
      "offset2_densities, offset2_bins = np.histogram(offset2_probs, bins=20)\n",
      "\n",
      "plt.plot(random_bins[:-1], random_densities, color=\"c\", label=\"Random\")\n",
      "plt.hold(True)\n",
      "plt.plot(offset1_bins[:-1], offset0_densities, color=\"r\", label=\"Offset 0\")\n",
      "plt.plot(offset1_bins[:-1], offset1_densities, color=\"g\", label=\"Offset 1\")\n",
      "plt.plot(offset2_bins[:-1], offset2_densities, color=\"b\", label=\"Offset 2\")\n",
      "plt.xlabel(\"Probability\", fontsize=16)\n",
      "plt.ylabel(\"Density\", fontsize=16)\n",
      "plt.legend(loc=\"upper right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_roc_curve(*triplets):\n",
      "    colors = [\"r\", \"g\", \"b\",]\n",
      "    c = 0\n",
      "    for label, word_classifications, mappings in triplets:\n",
      "        sorted_classif = sorted([(prob, orig, classif) for orig, classif, prob in word_classifications])\n",
      "        sorted_classif.reverse()\n",
      "        tp = 0.0\n",
      "        fp = 0.0\n",
      "        xs = []\n",
      "        ys = []\n",
      "        for _, orig, classif in sorted_classif:\n",
      "            if orig not in mappings:\n",
      "                continue\n",
      "            if mappings[orig] == classif:\n",
      "                tp += 1.0\n",
      "            else:\n",
      "                fp += 1.0\n",
      "            xs.append(fp / 1500.0)\n",
      "            ys.append(tp / 1500.0)\n",
      "        xs.append(1.0)\n",
      "        ys.append(1.0)\n",
      "        print label, tp / 1500.0, fp / 1500.0\n",
      "        plt.plot(xs, ys, color=colors[c], label=label)\n",
      "        c += 1\n",
      "        plt.hold(True)\n",
      "    plt.xlabel(\"Incorrect Class\")\n",
      "    plt.ylabel(\"Correct Class\")\n",
      "    plt.legend(loc=\"lower right\")\n",
      "\n",
      "triplets = [(\"Offset0\", offset0_word_set_classifications, validation_set_labels_0),\n",
      "            (\"Offset1\", offset1_word_set_classifications, validation_set_labels_1), \n",
      "            (\"Offset2\", offset2_word_set_classifications, validation_set_labels_2)]\n",
      "            \n",
      "plot_roc_curve(*triplets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Scikit Learn"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocabulary = dict()\n",
      "i = 0\n",
      "for group in [validation_word_sets, training_word_sets, validation_word_set_0, validation_word_set_1, validation_word_set_2, training_word_set_0, training_word_set_1, training_word_set_2]:\n",
      "    for label, words in group:\n",
      "        for w in words:\n",
      "            if w not in vocabulary:\n",
      "                vocabulary[w] = i\n",
      "                i += 1\n",
      "print len(vocabulary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_features(word_sets, vocab):\n",
      "    label_indices = []\n",
      "    labels = np.zeros((len(word_sets)), dtype=np.int32)\n",
      "    features = np.zeros((len(word_sets), len(vocab)), dtype=np.int32)\n",
      "    print features.shape\n",
      "    for label, words in word_sets:\n",
      "        label_indices.append(label)\n",
      "        labels[len(label_indices) - 1] = len(label_indices) - 1\n",
      "        for w in words:\n",
      "            j = vocabulary[w]\n",
      "            features[len(label_indices) - 1, j] = 1\n",
      "    \n",
      "    return features, label_indices, labels\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "validation_features, validation_label_indices, validation_labels = build_features(validation_word_sets, vocabulary)\n",
      "training_features, training_label_indices, training_labels = build_features(training_word_sets, vocabulary)\n",
      "validation_0_features, validation_0_label_indices, validation_0_labels = build_features(validation_word_set_0, vocabulary)\n",
      "validation_1_features, validation_1_label_indices, validation_1_labels = build_features(validation_word_set_1, vocabulary)\n",
      "validation_2_features, validation_2_label_indices, validation_2_labels = build_features(validation_word_set_2, vocabulary)\n",
      "training_0_features, training_0_label_indices, training_0_labels = build_features(training_word_set_0, vocabulary)\n",
      "training_1_features, training_1_label_indices, training_1_labels = build_features(training_word_set_1, vocabulary)\n",
      "training_2_features, training_2_label_indices, training_2_labels = build_features(training_word_set_2, vocabulary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "mnb_0 = MultinomialNB()\n",
      "mnb_0.fit(training_0_features, training_0_labels)\n",
      "predictions_0 = mnb_0.predict(validation_0_features)\n",
      "\n",
      "mnb_1 = MultinomialNB()\n",
      "mnb_1.fit(training_1_features, training_1_labels)\n",
      "predictions_1 = mnb_1.predict(validation_1_features)\n",
      "\n",
      "mnb_2 = MultinomialNB()\n",
      "mnb_2.fit(training_2_features, training_2_labels)\n",
      "predictions_2 = mnb_2.predict(validation_2_features)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_errors(quads):\n",
      "    for label, predictions, validation_label_indices, training_label_indices, mappings in quads:\n",
      "        tp = 0.0\n",
      "        fp = 0.0\n",
      "        n_samples = predictions.shape[0]\n",
      "        for s in xrange(n_samples):\n",
      "            orig_label = validation_label_indices[s]\n",
      "            pred_label = training_label_indices[predictions[s]]\n",
      "            \n",
      "            if orig_label not in mappings:\n",
      "                continue\n",
      "                \n",
      "            if mappings[orig_label] == pred_label:\n",
      "                tp += 1.0\n",
      "            else:\n",
      "                fp += 1.0\n",
      "                \n",
      "        print label, tp / 1500.0, fp / 1500.0\n",
      "\n",
      "quads = [(\"Offset0\", predictions_0, validation_0_label_indices, training_0_label_indices, validation_set_labels_0),\n",
      "         (\"Offset1\", predictions_1, validation_1_label_indices, training_1_label_indices, validation_set_labels_1),\n",
      "         (\"Offset2\", predictions_2, validation_2_label_indices, training_2_label_indices, validation_set_labels_2)]\n",
      "\n",
      "compute_errors(quads)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import BernoulliNB\n",
      "\n",
      "bnb_0 = BernoulliNB()\n",
      "bnb_0.fit(training_0_features, training_0_labels)\n",
      "bnb_predictions_0 = bnb_0.predict(validation_0_features)\n",
      "\n",
      "bnb_1 = BernoulliNB()\n",
      "bnb_1.fit(training_1_features, training_1_labels)\n",
      "bnb_predictions_1 = bnb_1.predict(validation_1_features)\n",
      "\n",
      "bnb_2 = BernoulliNB()\n",
      "bnb_2.fit(training_2_features, training_2_labels)\n",
      "bnb_predictions_2 = bnb_2.predict(validation_2_features)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_errors(quads):\n",
      "    for label, predictions, validation_label_indices, training_label_indices, mappings in quads:\n",
      "        tp = 0.0\n",
      "        fp = 0.0\n",
      "        n_samples = predictions.shape[0]\n",
      "        for s in xrange(n_samples):\n",
      "            orig_label = validation_label_indices[s]\n",
      "            pred_label = training_label_indices[predictions[s]]\n",
      "            \n",
      "            if orig_label not in mappings:\n",
      "                continue\n",
      "                \n",
      "            if mappings[orig_label] == pred_label:\n",
      "                tp += 1.0\n",
      "            else:\n",
      "                fp += 1.0\n",
      "                \n",
      "        print label, tp / 1500.0, fp / 1500.0\n",
      "\n",
      "quads = [(\"Offset0\", bnb_predictions_0, validation_0_label_indices, training_0_label_indices, validation_set_labels_0),\n",
      "         (\"Offset1\", bnb_predictions_1, validation_1_label_indices, training_1_label_indices, validation_set_labels_1),\n",
      "         (\"Offset2\", bnb_predictions_2, validation_2_label_indices, training_2_label_indices, validation_set_labels_2)]\n",
      "\n",
      "compute_errors(quads)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "mnb_0_05 = MultinomialNB(alpha=0.5)\n",
      "mnb_0_05.fit(training_0_features, training_0_labels)\n",
      "predictions_0_05 = mnb_0_05.predict(validation_0_features)\n",
      "\n",
      "mnb_1_05 = MultinomialNB(alpha=0.5)\n",
      "mnb_1_05.fit(training_1_features, training_1_labels)\n",
      "predictions_1_05 = mnb_1_05.predict(validation_1_features)\n",
      "\n",
      "mnb_2_05 = MultinomialNB(alpha=0.5)\n",
      "mnb_2_05.fit(training_2_features, training_2_labels)\n",
      "predictions_2_05 = mnb_2_05.predict(validation_2_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_errors(quads):\n",
      "    for label, predictions, validation_label_indices, training_label_indices, mappings in quads:\n",
      "        tp = 0.0\n",
      "        fp = 0.0\n",
      "        n_samples = predictions.shape[0]\n",
      "        for s in xrange(n_samples):\n",
      "            orig_label = validation_label_indices[s]\n",
      "            pred_label = training_label_indices[predictions[s]]\n",
      "            \n",
      "            if orig_label not in mappings:\n",
      "                continue\n",
      "                \n",
      "            if mappings[orig_label] == pred_label:\n",
      "                tp += 1.0\n",
      "            else:\n",
      "                fp += 1.0\n",
      "                \n",
      "        print label, tp / 1500.0, fp / 1500.0\n",
      "\n",
      "quads = [(\"Offset0\", predictions_0_05, validation_0_label_indices, training_0_label_indices, validation_set_labels_0),\n",
      "         (\"Offset1\", predictions_1_05, validation_1_label_indices, training_1_label_indices, validation_set_labels_1),\n",
      "         (\"Offset2\", predictions_2_05, validation_2_label_indices, training_2_label_indices, validation_set_labels_2)]\n",
      "\n",
      "compute_errors(quads)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(np.arange(0.01, 10, 0.01), np.log(np.arange(0.01, 10, 0.01)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}